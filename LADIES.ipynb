{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/LADIES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGAF4Yzg7-yP",
        "outputId": "383578b7-67e2-44fc-ee4c-5f56c9db4413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "2.6.0+cu124\n",
            "12.4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install torchvision\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDqorQ2B_cJa",
        "outputId": "7f7010a5-ce1e-4ee0-ab08-fd7c634bb7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt26cu124)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from torch_geometric.datasets import Planetoid, Amazon\n",
        "from torch_geometric.transforms import NormalizeFeatures, RandomNodeSplit\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "import json,time\n",
        "import gc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "nPHw6xV4-w4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_gpu_memory():\n",
        "    \"\"\"Cleans GPU memory without fully resetting the CUDA context\"\"\"\n",
        "    import gc\n",
        "    gc.collect()  # Python garbage collection\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # PyTorch cache\n",
        "        torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
        "        print(f\"Memory after cleanup: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "6PnI4iSN7k3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJqD_ARj_ZgH",
        "outputId": "fc7e0914-6767-4fd5-9f9b-b550ba6bba46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Ensure reproducibility\n",
        "def seed_everything(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def estimate_ladies_memory_MB(K, L, slayer):\n",
        "    bytes_per_float = 4  # float32\n",
        "    total_floats = L * K * slayer + L * K * K\n",
        "    total_bytes = total_floats * bytes_per_float\n",
        "    return total_bytes / (1024 ** 2)\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "\n",
        "# ------------------- Prepare Adjacency -------------------\n",
        "adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)\n",
        "lap_matrix = adj + sp.eye(adj.shape[0])\n",
        "\n",
        "def row_normalize(mx):\n",
        "    rowsum = np.array(mx.sum(1)).flatten()\n",
        "    rowsum[rowsum == 0] = 1  # Avoid division by zero\n",
        "    r_inv = np.power(rowsum, -1)\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    return r_mat_inv.dot(mx)\n",
        "\n",
        "\n",
        "lap_matrix = row_normalize(lap_matrix)\n",
        "\n",
        "# ------------------- Sampler -------------------\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert scipy sparse matrix to torch sparse tensor\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse_coo_tensor(indices, values, shape, device=device)\n",
        "def evaluate(model, features, adjs, labels, nodes):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(features, adjs)\n",
        "        preds = out[nodes].argmax(dim=1).cpu()\n",
        "        targets = labels[nodes].cpu()\n",
        "\n",
        "        acc = (preds == targets).float().mean().item()\n",
        "        f1_micro = f1_score(targets, preds, average='micro')\n",
        "\n",
        "    return acc, f1_micro\n",
        "\n",
        "def ladies_sampler(seed, batch_nodes, samp_num_list, num_nodes, lap_matrix, depth):\n",
        "    np.random.seed(seed)\n",
        "    previous_nodes = batch_nodes.cpu().numpy()\n",
        "    adjs = []\n",
        "    for d in range(depth):\n",
        "        U = lap_matrix[previous_nodes, :]\n",
        "        pi = np.array(np.sum(U.multiply(U), axis=0))[0]\n",
        "        p = pi / np.sum(pi)\n",
        "        s_num = np.min([np.sum(p > 0), samp_num_list[d]])\n",
        "        after_nodes = np.random.choice(num_nodes, s_num, p=p, replace=False)\n",
        "        after_nodes = np.unique(np.concatenate((after_nodes, batch_nodes.cpu().numpy())))\n",
        "        adj = U[:, after_nodes].multiply(1 / p[after_nodes])\n",
        "        adj = row_normalize(adj)\n",
        "        adjs.append(sparse_mx_to_torch_sparse_tensor(adj))\n",
        "        previous_nodes = after_nodes\n",
        "    adjs.reverse()\n",
        "    return adjs, torch.tensor(previous_nodes, device=device), batch_nodes\n",
        "\n",
        "# ------------------- Model -------------------\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.convs.append(nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (conv, adj) in enumerate(zip(self.convs[:-1], adjs)):\n",
        "            x = conv(x)\n",
        "            x = torch.sparse.mm(adj, x)\n",
        "            x = F.relu(x)\n",
        "        x = self.convs[-1](x)\n",
        "        return x\n",
        "\n",
        "# ------------------- Training -------------------\n",
        "model = GCN(num_features, 64, num_classes, num_layers=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_nodes = torch.where(data.train_mask)[0]\n",
        "valid_nodes = torch.where(data.val_mask)[0]\n",
        "labels = data.y\n",
        "features = data.x\n",
        "batch_size = 128\n",
        "samp_num_list = [64, 64]\n",
        "depth = len(samp_num_list)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(train_nodes.size(0), device=device)[:batch_size]\n",
        "    batch_nodes = train_nodes[idx]\n",
        "\n",
        "    adjs, input_nodes, output_nodes = ladies_sampler(\n",
        "        seed=np.random.randint(0, 100000),\n",
        "        batch_nodes=batch_nodes,\n",
        "        samp_num_list=samp_num_list,\n",
        "        num_nodes=data.num_nodes,\n",
        "        lap_matrix=lap_matrix,\n",
        "        depth=depth\n",
        "    )\n",
        "\n",
        "    out = model(features[input_nodes], adjs)\n",
        "    loss = criterion(out[output_nodes], labels[output_nodes])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "        acc, f1_micro = evaluate(model, features, [full_adj]*depth, labels, valid_nodes)\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {acc:.4f} | F1-micro: {f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "test_nodes = torch.where(data.test_mask)[0]\n",
        "full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "test_acc, test_f1 = evaluate(model, features, [full_adj]*depth, labels, test_nodes)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Test F1-micro: {test_f1:.4f}\")\n",
        "\n",
        "# LADIES theoretical memory\n",
        "K = 64         # hidden dimension\n",
        "L = 2          # number of layers\n",
        "slayer = 64    # number of sampled nodes per layer\n",
        "mem_MB = estimate_ladies_memory_MB(K, L, slayer)\n",
        "\n",
        "print(f\"Theoretical LADIES memory usage: {mem_MB:.2f} MB (embedding + transformation weights)\")\n",
        "\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# ------------------- GPU Usage -------------------\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used:  {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMQ0aYykE-it",
        "outputId": "5bfe7818-9574-42db-de5e-ddb4306c8b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 0.9537 | Val Acc: 0.7080 | F1-micro: 0.7080\n",
            "Epoch 020 | Loss: 0.6219 | Val Acc: 0.7440 | F1-micro: 0.7440\n",
            "Epoch 030 | Loss: 0.2689 | Val Acc: 0.7600 | F1-micro: 0.7600\n",
            "Epoch 040 | Loss: 0.1102 | Val Acc: 0.7660 | F1-micro: 0.7660\n",
            "Epoch 050 | Loss: 0.0542 | Val Acc: 0.7580 | F1-micro: 0.7580\n",
            "Epoch 060 | Loss: 0.0345 | Val Acc: 0.7560 | F1-micro: 0.7560\n",
            "Epoch 070 | Loss: 0.0155 | Val Acc: 0.7700 | F1-micro: 0.7700\n",
            "Epoch 080 | Loss: 0.0173 | Val Acc: 0.7540 | F1-micro: 0.7540\n",
            "Epoch 090 | Loss: 0.0102 | Val Acc: 0.7620 | F1-micro: 0.7620\n",
            "Epoch 100 | Loss: 0.0079 | Val Acc: 0.7700 | F1-micro: 0.7700\n",
            "Test Accuracy: 0.7450 | Test F1-micro: 0.7450\n",
            "Theoretical LADIES memory usage: 0.06 MB (embedding + transformation weights)\n",
            "Training time: 2.21 seconds\n",
            "GPU memory allocated: 61.21 MB\n",
            "Max GPU memory used:  83.03 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"Ladies\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":mem_MB\n",
        "}\n",
        "\n",
        "with open(\"Ladies_pubmed_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "sq7-ArWa5Hty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cora**"
      ],
      "metadata": {
        "id": "KqxWp-2z7bgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)\n",
        "lap_matrix = adj + sp.eye(adj.shape[0])\n",
        "lap_matrix = row_normalize(lap_matrix)\n",
        "model = GCN(num_features, 64, num_classes, num_layers=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_nodes = torch.where(data.train_mask)[0]\n",
        "valid_nodes = torch.where(data.val_mask)[0]\n",
        "labels = data.y\n",
        "features = data.x\n",
        "batch_size = 128\n",
        "samp_num_list = [64, 64]\n",
        "depth = len(samp_num_list)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(train_nodes.size(0), device=device)[:batch_size]\n",
        "    batch_nodes = train_nodes[idx]\n",
        "\n",
        "    adjs, input_nodes, output_nodes = ladies_sampler(\n",
        "        seed=np.random.randint(0, 100000),\n",
        "        batch_nodes=batch_nodes,\n",
        "        samp_num_list=samp_num_list,\n",
        "        num_nodes=data.num_nodes,\n",
        "        lap_matrix=lap_matrix,\n",
        "        depth=depth\n",
        "    )\n",
        "\n",
        "    out = model(features[input_nodes], adjs)\n",
        "    loss = criterion(out[output_nodes], labels[output_nodes])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "        acc, f1_micro = evaluate(model, features, [full_adj]*depth, labels, valid_nodes)\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {acc:.4f} | F1-micro: {f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "test_nodes = torch.where(data.test_mask)[0]\n",
        "full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "test_acc, test_f1 = evaluate(model, features, [full_adj]*depth, labels, test_nodes)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Test F1-micro: {test_f1:.4f}\")\n",
        "\n",
        "# LADIES theoretical memory\n",
        "K = 64         # hidden dimension\n",
        "L = 2          # number of layers\n",
        "slayer = 64    # number of sampled nodes per layer\n",
        "mem_MB = estimate_ladies_memory_MB(K, L, slayer)\n",
        "\n",
        "print(f\"Theoretical LADIES memory usage: {mem_MB:.2f} MB (embedding + transformation weights)\")\n",
        "\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# ------------------- GPU Usage -------------------\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used:  {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYeRKAjw7fkf",
        "outputId": "3f5882ac-63bc-4324-971e-990a757f8e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 58.40 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 1.9201 | Val Acc: 0.3540 | F1-micro: 0.3540\n",
            "Epoch 020 | Loss: 1.8112 | Val Acc: 0.3320 | F1-micro: 0.3320\n",
            "Epoch 030 | Loss: 1.7370 | Val Acc: 0.3460 | F1-micro: 0.3460\n",
            "Epoch 040 | Loss: 1.6298 | Val Acc: 0.2460 | F1-micro: 0.2460\n",
            "Epoch 050 | Loss: 1.5298 | Val Acc: 0.2880 | F1-micro: 0.2880\n",
            "Epoch 060 | Loss: 1.4164 | Val Acc: 0.2760 | F1-micro: 0.2760\n",
            "Epoch 070 | Loss: 1.3651 | Val Acc: 0.2340 | F1-micro: 0.2340\n",
            "Epoch 080 | Loss: 1.2404 | Val Acc: 0.2820 | F1-micro: 0.2820\n",
            "Epoch 090 | Loss: 1.2279 | Val Acc: 0.2420 | F1-micro: 0.2420\n",
            "Epoch 100 | Loss: 1.2857 | Val Acc: 0.2060 | F1-micro: 0.2060\n",
            "Test Accuracy: 0.2380 | Test F1-micro: 0.2380\n",
            "Theoretical LADIES memory usage: 0.06 MB (embedding + transformation weights)\n",
            "Training time: 1.38 seconds\n",
            "GPU memory allocated: 33.23 MB\n",
            "Max GPU memory used:  75.76 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"Ladies\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":mem_MB\n",
        "}\n",
        "\n",
        "with open(\"Ladies_cora_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "9GYbgx3r8PNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Citeser**"
      ],
      "metadata": {
        "id": "0WUyOoJF8Z9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)\n",
        "lap_matrix = adj + sp.eye(adj.shape[0])\n",
        "lap_matrix = row_normalize(lap_matrix)\n",
        "model = GCN(num_features, 64, num_classes, num_layers=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_nodes = torch.where(data.train_mask)[0]\n",
        "valid_nodes = torch.where(data.val_mask)[0]\n",
        "labels = data.y\n",
        "features = data.x\n",
        "batch_size = 128\n",
        "samp_num_list = [64, 64]\n",
        "depth = len(samp_num_list)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(train_nodes.size(0), device=device)[:batch_size]\n",
        "    batch_nodes = train_nodes[idx]\n",
        "\n",
        "    adjs, input_nodes, output_nodes = ladies_sampler(\n",
        "        seed=np.random.randint(0, 100000),\n",
        "        batch_nodes=batch_nodes,\n",
        "        samp_num_list=samp_num_list,\n",
        "        num_nodes=data.num_nodes,\n",
        "        lap_matrix=lap_matrix,\n",
        "        depth=depth\n",
        "    )\n",
        "\n",
        "    out = model(features[input_nodes], adjs)\n",
        "    loss = criterion(out[output_nodes], labels[output_nodes])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "        acc, f1_micro = evaluate(model, features, [full_adj]*depth, labels, valid_nodes)\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {acc:.4f} | F1-micro: {f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "test_nodes = torch.where(data.test_mask)[0]\n",
        "full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "test_acc, test_f1 = evaluate(model, features, [full_adj]*depth, labels, test_nodes)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Test F1-micro: {test_f1:.4f}\")\n",
        "\n",
        "# LADIES theoretical memory\n",
        "K = 64         # hidden dimension\n",
        "L = 2          # number of layers\n",
        "slayer = 64    # number of sampled nodes per layer\n",
        "mem_MB = estimate_ladies_memory_MB(K, L, slayer)\n",
        "\n",
        "print(f\"Theoretical LADIES memory usage: {mem_MB:.2f} MB (embedding + transformation weights)\")\n",
        "\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# ------------------- GPU Usage -------------------\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used:  {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbM-R9tN8d5d",
        "outputId": "4bf1d4fc-f88e-4c76-a109-17701bd03faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 32.95 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 1.6401 | Val Acc: 0.4960 | F1-micro: 0.4960\n",
            "Epoch 020 | Loss: 1.1947 | Val Acc: 0.5660 | F1-micro: 0.5660\n",
            "Epoch 030 | Loss: 0.6185 | Val Acc: 0.5860 | F1-micro: 0.5860\n",
            "Epoch 040 | Loss: 0.2521 | Val Acc: 0.6100 | F1-micro: 0.6100\n",
            "Epoch 050 | Loss: 0.1264 | Val Acc: 0.5960 | F1-micro: 0.5960\n",
            "Epoch 060 | Loss: 0.0935 | Val Acc: 0.6160 | F1-micro: 0.6160\n",
            "Epoch 070 | Loss: 0.0679 | Val Acc: 0.6300 | F1-micro: 0.6300\n",
            "Epoch 080 | Loss: 0.0593 | Val Acc: 0.6260 | F1-micro: 0.6260\n",
            "Epoch 090 | Loss: 0.0573 | Val Acc: 0.6240 | F1-micro: 0.6240\n",
            "Epoch 100 | Loss: 0.0594 | Val Acc: 0.6220 | F1-micro: 0.6220\n",
            "Test Accuracy: 0.6340 | Test F1-micro: 0.6340\n",
            "Theoretical LADIES memory usage: 0.06 MB (embedding + transformation weights)\n",
            "Training time: 1.39 seconds\n",
            "GPU memory allocated: 67.58 MB\n",
            "Max GPU memory used:  86.30 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"Ladies\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":mem_MB\n",
        "}\n",
        "\n",
        "with open(\"Ladies_citeser_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "2x6He7no8meh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amazon dataset**"
      ],
      "metadata": {
        "id": "qB5NUpJd8wCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmw7b6C8DbTf",
        "outputId": "61fed249-531a-4de0-b4eb-07d981d878a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 67.32 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(data, train_ratio=0.6, val_ratio=0.2, seed=42):\n",
        "    y = data.y.cpu().numpy()\n",
        "    idx = np.arange(len(y))\n",
        "    train_idx, temp_idx = train_test_split(\n",
        "        idx, stratify=y, train_size=train_ratio, random_state=seed)\n",
        "    val_idx, test_idx = train_test_split(\n",
        "        temp_idx, stratify=y[temp_idx], test_size=0.5, random_state=seed)\n",
        "\n",
        "    data.train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
        "    data.val_mask   = torch.zeros(len(y), dtype=torch.bool)\n",
        "    data.test_mask  = torch.zeros(len(y), dtype=torch.bool)\n",
        "    data.train_mask[train_idx] = True\n",
        "    data.val_mask[val_idx]     = True\n",
        "    data.test_mask[test_idx]   = True\n",
        "    return data\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def estimate_ladies_memory_MB(K, L, slayer):\n",
        "    bytes_per_float = 4  # float32\n",
        "    total_floats = L * K * slayer + L * K * K\n",
        "    total_bytes = total_floats * bytes_per_float\n",
        "    return total_bytes / (1024 ** 2)\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "dataset = Amazon(root='data/Amazon', name='Computers', transform=NormalizeFeatures())\n",
        "data    = dataset[0]\n",
        "data    = stratified_split(data)        # create masks\n",
        "data    = data.to(device)\n",
        "num_features, num_classes = dataset.num_features, dataset.num_classes\n",
        "\n",
        "\n",
        "# ------------------- Prepare Adjacency -------------------\n",
        "adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)\n",
        "lap_matrix = adj + sp.eye(adj.shape[0])\n",
        "\n",
        "def row_normalize(mx):\n",
        "    rowsum = np.array(mx.sum(1)).flatten()\n",
        "    rowsum[rowsum == 0] = 1  # Avoid division by zero\n",
        "    r_inv = np.power(rowsum, -1)\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    return r_mat_inv.dot(mx)\n",
        "\n",
        "\n",
        "lap_matrix = row_normalize(lap_matrix)\n",
        "\n",
        "# ------------------- Sampler -------------------\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert scipy sparse matrix to torch sparse tensor\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse_coo_tensor(indices, values, shape, device=device)\n",
        "def evaluate(model, features, adjs, labels, nodes):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(features, adjs)\n",
        "        preds = out[nodes].argmax(dim=1).cpu()\n",
        "        targets = labels[nodes].cpu()\n",
        "\n",
        "        acc = (preds == targets).float().mean().item()\n",
        "        f1_micro = f1_score(targets, preds, average='micro')\n",
        "\n",
        "    return acc, f1_micro\n",
        "\n",
        "def ladies_sampler(seed, batch_nodes, samp_num_list, num_nodes, lap_matrix, depth):\n",
        "    np.random.seed(seed)\n",
        "    previous_nodes = batch_nodes.cpu().numpy()\n",
        "    adjs = []\n",
        "    for d in range(depth):\n",
        "        U = lap_matrix[previous_nodes, :]\n",
        "        pi = np.array(np.sum(U.multiply(U), axis=0))[0]\n",
        "        p = pi / np.sum(pi)\n",
        "        s_num = np.min([np.sum(p > 0), samp_num_list[d]])\n",
        "        after_nodes = np.random.choice(num_nodes, s_num, p=p, replace=False)\n",
        "        after_nodes = np.unique(np.concatenate((after_nodes, batch_nodes.cpu().numpy())))\n",
        "        adj = U[:, after_nodes].multiply(1 / p[after_nodes])\n",
        "        adj = row_normalize(adj)\n",
        "        adjs.append(sparse_mx_to_torch_sparse_tensor(adj))\n",
        "        previous_nodes = after_nodes\n",
        "    adjs.reverse()\n",
        "    return adjs, torch.tensor(previous_nodes, device=device), batch_nodes\n",
        "\n",
        "# ------------------- Model -------------------\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.convs.append(nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (conv, adj) in enumerate(zip(self.convs[:-1], adjs)):\n",
        "            x = conv(x)\n",
        "            x = torch.sparse.mm(adj, x)\n",
        "            x = F.relu(x)\n",
        "        x = self.convs[-1](x)\n",
        "        return x\n",
        "\n",
        "# ------------------- Training -------------------\n",
        "model = GCN(num_features, 64, num_classes, num_layers=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_nodes = torch.where(data.train_mask)[0]\n",
        "valid_nodes = torch.where(data.val_mask)[0]\n",
        "labels = data.y\n",
        "features = data.x\n",
        "batch_size = 128\n",
        "samp_num_list = [64, 64]\n",
        "depth = len(samp_num_list)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(train_nodes.size(0), device=device)[:batch_size]\n",
        "    batch_nodes = train_nodes[idx]\n",
        "\n",
        "    adjs, input_nodes, output_nodes = ladies_sampler(\n",
        "        seed=np.random.randint(0, 100000),\n",
        "        batch_nodes=batch_nodes,\n",
        "        samp_num_list=samp_num_list,\n",
        "        num_nodes=data.num_nodes,\n",
        "        lap_matrix=lap_matrix,\n",
        "        depth=depth\n",
        "    )\n",
        "\n",
        "    out = model(features[input_nodes], adjs)\n",
        "    loss = criterion(out[output_nodes], labels[output_nodes])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "        acc, f1_micro = evaluate(model, features, [full_adj]*depth, labels, valid_nodes)\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {acc:.4f} | F1-micro: {f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "test_nodes = torch.where(data.test_mask)[0]\n",
        "full_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj + sp.eye(adj.shape[0])))\n",
        "test_acc, test_f1 = evaluate(model, features, [full_adj]*depth, labels, test_nodes)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Test F1-micro: {test_f1:.4f}\")`"
      ],
      "metadata": {
        "id": "VHQunOzo-BKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}