{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOs/5i+a6AbKdnBXY6YGRGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/test_gcn_variants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x5loG4i3uJp",
        "outputId": "106cb174-cb7d-4431-d27c-cd0155766877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgoD1Pkr_fXV",
        "outputId": "b100c7fd-8c4d-4538-8b9e-204c8d6690e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DayBwOJd_mKn",
        "outputId": "ae813654-b846-4b60-da5c-6fa9639fedef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4kz6bH_pnL",
        "outputId": "4c0ea449-685a-401c-e933-6ca13b199daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from matplotlib import cm\n",
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "# import pyg_lib\n",
        "import torch_sparse\n",
        "\n",
        "# PyTorch geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.loader import ClusterData, ClusterLoader\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric import seed_everything"
      ],
      "metadata": {
        "id": "F1xbmd_1AJxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(1234567)\n",
        "seed_everything(42)\n",
        "plt.style.use('dark_background')\n",
        "num_epochs = 101"
      ],
      "metadata": {
        "id": "djZb3AuzB5hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "num_features = dataset.num_features\n",
        "num_classes = dataset.num_classes\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIPzKlZCDAm",
        "outputId": "ce9f534e-b548-4ef9-d8c6-314822b77bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of nodes:          {data.num_nodes}')\n",
        "print(f'Number of edges:          {data.num_edges}')\n",
        "print(f'Average node degree:      {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
        "print(f'Has isolated nodes:       {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops:           {data.has_self_loops()}')\n",
        "print(f'Is undirected:            {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_68HoG0CFvQ",
        "outputId": "61872be2-28cb-43c4-cd89-6f73caa4f734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes:          19717\n",
            "Number of edges:          88648\n",
            "Average node degree:      4.50\n",
            "Number of training nodes: 60\n",
            "Training node label rate: 0.003\n",
            "Has isolated nodes:       False\n",
            "Has self-loops:           False\n",
            "Is undirected:            True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = x.relu()\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    return x"
      ],
      "metadata": {
        "id": "WO1wwKbMCGbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STANDARD GCN**"
      ],
      "metadata": {
        "id": "XqGIH2c8CdHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoV5H-7JCLrB",
        "outputId": "0b276c85-b16a-4180-e54a-9fed7d651351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(500, 16)\n",
            "  (conv2): GCNConv(16, 3)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, mask):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()  # Clear gradients.\n",
        "  out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
        "  loss = criterion(out[mask], data.y[mask])  # Compute the loss solely based on the training nodes.\n",
        "  loss.backward()  # Derive gradients.\n",
        "  optimizer.step()  # Update parameters based on gradients.\n",
        "  return loss\n",
        "\n",
        "def test(data, mask):\n",
        "  model.eval()\n",
        "  out = model(data.x, data.edge_index)\n",
        "  pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "  correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
        "  acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
        "  return acc"
      ],
      "metadata": {
        "id": "DU2MmFAXCN2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "for epoch in range(1, num_epochs):\n",
        "  loss = train(data, data.train_mask)\n",
        "  if epoch % 10 == 0:\n",
        "    train_acc = test(data, data.train_mask)\n",
        "    val_acc = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "170T7bBCCR8l",
        "outputId": "030635f2-b485-4bd0-f429-795730b021bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Train: 0.9167\n",
            "Epoch: 020, Train: 0.9333\n",
            "Epoch: 030, Train: 0.9333\n",
            "Epoch: 040, Train: 0.9500\n",
            "Epoch: 050, Train: 0.9500\n",
            "Epoch: 060, Train: 0.9667\n",
            "Epoch: 070, Train: 0.9667\n",
            "Epoch: 080, Train: 0.9833\n",
            "Epoch: 090, Train: 1.0000\n",
            "Epoch: 100, Train: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test(data, data.test_mask)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEytRA11CZTv",
        "outputId": "c367386e-7ad3-462a-d606-32a53eb24d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.766"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLUSTER GCN**"
      ],
      "metadata": {
        "id": "pMfsq-w5Cjmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_data = ClusterData(data, num_parts=128)\n",
        "train_loader = ClusterLoader(cluster_data, batch_size=32, shuffle=True)\n",
        "\n",
        "total_num_nodes = 0\n",
        "for step, sub_data in enumerate(train_loader):\n",
        "  print(f'Batch: {step + 1} has {sub_data.num_nodes} nodes')\n",
        "  print(sub_data)\n",
        "  print()\n",
        "  total_num_nodes += sub_data.num_nodes\n",
        "\n",
        "print(f'Iterated over {total_num_nodes} of {data.num_nodes} nodes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6OxssB-CnN9",
        "outputId": "581cb64c-9290-48ea-a313-3411c97ec1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing METIS partitioning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 1 has 4961 nodes\n",
            "Data(x=[4961, 500], y=[4961], train_mask=[4961], val_mask=[4961], test_mask=[4961], edge_index=[2, 17856])\n",
            "\n",
            "Batch: 2 has 4912 nodes\n",
            "Data(x=[4912, 500], y=[4912], train_mask=[4912], val_mask=[4912], test_mask=[4912], edge_index=[2, 17472])\n",
            "\n",
            "Batch: 3 has 4915 nodes\n",
            "Data(x=[4915, 500], y=[4915], train_mask=[4915], val_mask=[4915], test_mask=[4915], edge_index=[2, 16548])\n",
            "\n",
            "Batch: 4 has 4929 nodes\n",
            "Data(x=[4929, 500], y=[4929], train_mask=[4929], val_mask=[4929], test_mask=[4929], edge_index=[2, 14892])\n",
            "\n",
            "Iterated over 19717 of 19717 nodes!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(loader):\n",
        "  model.train()\n",
        "  for sub_data in train_loader:  # Iterate over each mini-batch.\n",
        "    out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
        "    loss = criterion(out[sub_data.train_mask], sub_data.y[sub_data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    optimizer.zero_grad()  # Clear gradients."
      ],
      "metadata": {
        "id": "1mca-m_ECtZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "for epoch in range(1, num_epochs):\n",
        "  loss = train_batch(train_loader)\n",
        "  if epoch % 10 == 0:\n",
        "    train_acc = test(data, data.train_mask)\n",
        "    val_acc = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "5EpNNohtCz5t",
        "outputId": "da65e6d2-e071-41bb-a08a-c016081edbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Train: 0.9333\n",
            "Epoch: 020, Train: 0.9833\n",
            "Epoch: 030, Train: 1.0000\n",
            "Epoch: 040, Train: 1.0000\n",
            "Epoch: 050, Train: 1.0000\n",
            "Epoch: 060, Train: 1.0000\n",
            "Epoch: 070, Train: 1.0000\n",
            "Epoch: 080, Train: 1.0000\n",
            "Epoch: 090, Train: 1.0000\n",
            "Epoch: 100, Train: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test(data, data.test_mask)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjbB-MLbC7zk",
        "outputId": "67952d09-f30a-4526-d7bb-0e3a89964e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.773"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GraphSAGE**"
      ],
      "metadata": {
        "id": "djoXaFrhOmPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.nn import GraphSAGE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "\n",
        "# Create neighbor loader for mini-batch training\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[10, 10],  # 2 layers with 10 neighbors each\n",
        "    batch_size=1024,\n",
        "    input_nodes=data.train_mask,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Initialize GraphSAGE model (similar hidden size to GCN)\n",
        "model = GraphSAGE(\n",
        "    in_channels=dataset.num_features,  # 500 for PubMed\n",
        "    hidden_channels=16,               # Same as GCN\n",
        "    num_layers=2,                     # 2-layer model\n",
        "    out_channels=dataset.num_classes, # 3 for PubMed\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Same LR as GCN\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = total_correct = total_examples = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = F.cross_entropy(out[batch.train_mask], batch.y[batch.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss) * batch.train_mask.sum()\n",
        "        total_correct += int((out[batch.train_mask].argmax(dim=-1) == batch.y[batch.train_mask]).sum())\n",
        "        total_examples += batch.train_mask.sum()\n",
        "\n",
        "    return total_loss / total_examples, total_correct / total_examples\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=-1)\n",
        "    acc = accuracy_score(data.y[mask].cpu(), pred[mask].cpu())\n",
        "    return acc\n",
        "\n",
        "# Training loop (same number of epochs as GCN)\n",
        "for epoch in range(1, 101):\n",
        "    loss, train_acc = train()\n",
        "    if epoch % 10 == 0:\n",
        "        val_acc = test(data.val_mask)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}')\n",
        "\n",
        "# Final testing\n",
        "test_acc = test(data.test_mask)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UutKc_e2Op-y",
        "outputId": "c602b8f1-16af-4df8-b72f-d43d1dbeb880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.9164, Train: 0.9667, Val: 0.7160\n",
            "Epoch: 020, Loss: 0.5277, Train: 0.9833, Val: 0.7400\n",
            "Epoch: 030, Loss: 0.2005, Train: 0.9833, Val: 0.7560\n",
            "Epoch: 040, Loss: 0.0689, Train: 1.0000, Val: 0.7600\n",
            "Epoch: 050, Loss: 0.0272, Train: 1.0000, Val: 0.7640\n",
            "Epoch: 060, Loss: 0.0146, Train: 1.0000, Val: 0.7640\n",
            "Epoch: 070, Loss: 0.0089, Train: 1.0000, Val: 0.7680\n",
            "Epoch: 080, Loss: 0.0073, Train: 1.0000, Val: 0.7660\n",
            "Epoch: 090, Loss: 0.0059, Train: 1.0000, Val: 0.7680\n",
            "Epoch: 100, Loss: 0.0047, Train: 1.0000, Val: 0.7720\n",
            "Test Accuracy: 0.7460\n"
          ]
        }
      ]
    }
  ]
}