{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgqawWrIYjDcqYF9/Gli93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/test_gcn_variants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x5loG4i3uJp",
        "outputId": "12163c99-24d1-4eaa-bcd6-0e6cdf793d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgoD1Pkr_fXV",
        "outputId": "ad10d7f2-6a69-4d0b-d482-6413ad7db453"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DayBwOJd_mKn",
        "outputId": "13c8e519-bdcd-43e1-f83d-bfc214109de3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KkCxJS-YSz_",
        "outputId": "3b022d6d-cb8c-4379-f3e5-e6b996873875"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4kz6bH_pnL",
        "outputId": "e0019e4e-a7b4-442b-df82-fa2509e56e7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt26cu124)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Plotting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from matplotlib import cm\n",
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch.nn as nn\n",
        "# import pyg_lib\n",
        "import torch_sparse\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# PyTorch geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid, Amazon\n",
        "from torch_geometric.loader import ClusterData, ClusterLoader\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric import seed_everything\n",
        "from torch_geometric.nn.models import GraphSAGE\n",
        "from torch_geometric.transforms import NormalizeFeatures, RandomNodeSplit\n",
        "import torch_geometric.transforms as T\n",
        "import json\n"
      ],
      "metadata": {
        "id": "F1xbmd_1AJxm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STANDARD GCN pubmed**"
      ],
      "metadata": {
        "id": "XqGIH2c8CdHw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djZb3AuzB5hz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "num_features = dataset.num_features\n",
        "num_classes = dataset.num_classes\n",
        "data = dataset[0].to(device)  # Get the first graph object.\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIPzKlZCDAm",
        "outputId": "e72b2e2e-b302-4610-c833-8cdee0ebc54d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of nodes:          {data.num_nodes}')\n",
        "print(f'Number of edges:          {data.num_edges}')\n",
        "print(f'Average node degree:      {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
        "print(f'Has isolated nodes:       {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops:           {data.has_self_loops()}')\n",
        "print(f'Is undirected:            {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_68HoG0CFvQ",
        "outputId": "b2abe3ac-4da5-4ea8-cf13-fc7daaf1fbb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes:          19717\n",
            "Number of edges:          88648\n",
            "Average node degree:      4.50\n",
            "Number of training nodes: 60\n",
            "Training node label rate: 0.003\n",
            "Has isolated nodes:       False\n",
            "Has self-loops:           False\n",
            "Is undirected:            True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_gpu_memory():\n",
        "    \"\"\"Cleans GPU memory without fully resetting the CUDA context\"\"\"\n",
        "    import gc\n",
        "    gc.collect()  # Python garbage collection\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # PyTorch cache\n",
        "        torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
        "        print(f\"Memory after cleanup: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "oHQAaCSmc3wI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "WO1wwKbMCGbE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_features, 64, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoV5H-7JCLrB",
        "outputId": "7676b12e-b815-4445-b11a-47d473e0e8e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(500, 64)\n",
            "  (conv2): GCNConv(64, 3)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, mask):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()  # Clear gradients.\n",
        "  out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
        "  loss = criterion(out[mask], data.y[mask])  # Compute the loss solely based on the training nodes.\n",
        "  loss.backward()  # Derive gradients.\n",
        "  optimizer.step()  # Update parameters based on gradients.\n",
        "  return loss\n",
        "\n",
        "def test(data, mask):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    true = data.y[mask].cpu()\n",
        "    pred = pred[mask].cpu()\n",
        "    acc = (pred == true).sum().item() / mask.sum().item()\n",
        "    micro_f1 = f1_score(true, pred, average='micro')\n",
        "    return acc, micro_f1\n"
      ],
      "metadata": {
        "id": "DU2MmFAXCN2u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train(data, data.train_mask)\n",
        "    train_acc, train_f1 = test(data, data.train_mask)\n",
        "    val_acc, val_f1 = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "170T7bBCCR8l",
        "outputId": "b2507a36-30b4-452f-a77a-269c96717cc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.5500, Train F1: 0.5500, Val Acc: 0.4780, Val F1: 0.4780\n",
            "Epoch: 002, Train Acc: 0.7167, Train F1: 0.7167, Val Acc: 0.5920, Val F1: 0.5920\n",
            "Epoch: 003, Train Acc: 0.8000, Train F1: 0.8000, Val Acc: 0.6560, Val F1: 0.6560\n",
            "Epoch: 004, Train Acc: 0.8833, Train F1: 0.8833, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 005, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7180, Val F1: 0.7180\n",
            "Epoch: 006, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7300, Val F1: 0.7300\n",
            "Epoch: 007, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7240, Val F1: 0.7240\n",
            "Epoch: 008, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7240, Val F1: 0.7240\n",
            "Epoch: 009, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7220, Val F1: 0.7220\n",
            "Epoch: 010, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7360, Val F1: 0.7360\n",
            "Epoch: 011, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7400, Val F1: 0.7400\n",
            "Epoch: 012, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 013, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.7480, Val F1: 0.7480\n",
            "Epoch: 014, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7400, Val F1: 0.7400\n",
            "Epoch: 015, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 016, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 017, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 018, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7400, Val F1: 0.7400\n",
            "Epoch: 019, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7400, Val F1: 0.7400\n",
            "Epoch: 020, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 021, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7480, Val F1: 0.7480\n",
            "Epoch: 022, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7480, Val F1: 0.7480\n",
            "Epoch: 023, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7500, Val F1: 0.7500\n",
            "Epoch: 024, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7540, Val F1: 0.7540\n",
            "Epoch: 025, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7540, Val F1: 0.7540\n",
            "Epoch: 026, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7600, Val F1: 0.7600\n",
            "Epoch: 027, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7600, Val F1: 0.7600\n",
            "Epoch: 028, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7600, Val F1: 0.7600\n",
            "Epoch: 029, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7600, Val F1: 0.7600\n",
            "Epoch: 030, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7620, Val F1: 0.7620\n",
            "Epoch: 031, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7620, Val F1: 0.7620\n",
            "Epoch: 032, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7660, Val F1: 0.7660\n",
            "Epoch: 033, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7660, Val F1: 0.7660\n",
            "Epoch: 034, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.7640, Val F1: 0.7640\n",
            "Epoch: 035, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.7680, Val F1: 0.7680\n",
            "Epoch: 036, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.7660, Val F1: 0.7660\n",
            "Epoch: 037, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7680, Val F1: 0.7680\n",
            "Epoch: 038, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7680, Val F1: 0.7680\n",
            "Epoch: 039, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7640, Val F1: 0.7640\n",
            "Epoch: 040, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7680, Val F1: 0.7680\n",
            "Epoch: 041, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7680, Val F1: 0.7680\n",
            "Epoch: 042, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.7700, Val F1: 0.7700\n",
            "Epoch: 043, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 044, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 045, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 046, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 047, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 048, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 049, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 050, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 051, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 052, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 053, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 054, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 055, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 056, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 057, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 058, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 059, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 060, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 061, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 062, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 063, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 064, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 065, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 066, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 067, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 068, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 069, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 070, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 071, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 072, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 073, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 074, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 075, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 076, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 077, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 078, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 079, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 080, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 081, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 082, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 083, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 084, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 085, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 086, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Epoch: 087, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7700, Val F1: 0.7700\n",
            "Epoch: 088, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7700, Val F1: 0.7700\n",
            "Epoch: 089, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7700, Val F1: 0.7700\n",
            "Epoch: 090, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7720, Val F1: 0.7720\n",
            "Epoch: 091, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 092, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 093, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 094, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 095, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 096, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 097, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 098, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 099, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 100, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7740, Val F1: 0.7740\n",
            "Current GPU memory: 56.31 MB\n",
            "Max GPU memory used: 120.92 MB\n",
            "Time taken: 2.56 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc,f1_micro = test(data, data.test_mask)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEytRA11CZTv",
        "outputId": "6a24ce88-2a00-4efd-85ce-ff344f20c63a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.759"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(data.x, data.edge_index)"
      ],
      "metadata": {
        "id": "3fixWNKucuNM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gcn_memory_usage(num_layers: int, num_nodes: int, feat_dim: int, use_bytes: bool = True):\n",
        "\n",
        "    # Each embedding matrix is size |V| × K floats, there are L such layers\n",
        "    num_emb_floats = num_layers * num_nodes * feat_dim\n",
        "    # Each weight matrix is K × K floats per layer\n",
        "    num_weight_floats = num_layers * feat_dim * feat_dim\n",
        "\n",
        "    if use_bytes:\n",
        "        bytes_per_float = 4  # assuming float32\n",
        "        embeddings_bytes = num_emb_floats * bytes_per_float\n",
        "        weights_bytes = num_weight_floats * bytes_per_float\n",
        "        total_bytes = embeddings_bytes + weights_bytes\n",
        "        return embeddings_bytes, weights_bytes, total_bytes\n",
        "    else:\n",
        "        return num_emb_floats, num_weight_floats, num_emb_floats + num_weight_floats\n",
        "\n",
        "\n",
        "e, w, t = gcn_memory_usage(2, data.num_nodes, out.shape[1])\n",
        "print(f\"Embeddings: {e/1e6:.1f} MB, Weights: {w*4/1e6:.1f} MB, Total: {t/1e6:.1f} MB\")\n",
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"GCN full-batch\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"embedding_storage\":e,\n",
        "    \"Weight_Matrices\":w,\n",
        "    \"Total_Memory\":t\n",
        "}\n",
        "\n",
        "with open(\"GCN_full_batch_pubmed_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "YpVvpb23YxmE",
        "outputId": "b7e7d4e2-e322-45b3-cedf-8a82edf5bf50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings: 0.5 MB, Weights: 0.0 MB, Total: 0.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cora dataset**"
      ],
      "metadata": {
        "id": "rjE_S1PJ9Gae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "num_features = dataset.num_features\n",
        "num_classes = dataset.num_classes\n",
        "data = dataset[0].to(device)  # Get the first graph object.\n",
        "data\n",
        "print(f'Number of nodes:          {data.num_nodes}')\n",
        "print(f'Number of edges:          {data.num_edges}')\n",
        "print(f'Average node degree:      {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
        "print(f'Has isolated nodes:       {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops:           {data.has_self_loops()}')\n",
        "print(f'Is undirected:            {data.is_undirected()}')\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_features, 64, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train(data, data.train_mask)\n",
        "    train_acc, train_f1 = test(data, data.train_mask)\n",
        "    val_acc, val_f1 = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "test_acc,f1_micro = test(data, data.test_mask)\n",
        "test_acc\n",
        "out = model(data.x, data.edge_index)\n",
        "e, w, t = gcn_memory_usage(2, data.num_nodes, out.shape[1])\n",
        "print(f\"Embeddings: {e/1e6:.1f} MB, Weights: {w*4/1e6:.1f} MB, Total: {t/1e6:.1f} MB\")\n",
        "\n",
        "\n",
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"GCN full-batch\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"embedding_storage\":e,\n",
        "    \"Weight_Matrices\":w,\n",
        "    \"Total_Memory\":t\n",
        "}\n",
        "\n",
        "with open(\"GCN_full_batch_cora_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "18hVrUko9KGA",
        "outputId": "a7d4e6a0-480d-4c72-a663-e109f21abdb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 65.48 MB\n",
            "Using device: cuda\n",
            "Number of nodes:          2708\n",
            "Number of edges:          10556\n",
            "Average node degree:      3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.052\n",
            "Has isolated nodes:       False\n",
            "Has self-loops:           False\n",
            "Is undirected:            True\n",
            "Epoch: 001, Train Acc: 0.6071, Train F1: 0.6071, Val Acc: 0.3940, Val F1: 0.3940\n",
            "Epoch: 002, Train Acc: 0.8643, Train F1: 0.8643, Val Acc: 0.5440, Val F1: 0.5440\n",
            "Epoch: 003, Train Acc: 0.9786, Train F1: 0.9786, Val Acc: 0.7380, Val F1: 0.7380\n",
            "Epoch: 004, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.7520, Val F1: 0.7520\n",
            "Epoch: 005, Train Acc: 0.9286, Train F1: 0.9286, Val Acc: 0.7480, Val F1: 0.7480\n",
            "Epoch: 006, Train Acc: 0.9357, Train F1: 0.9357, Val Acc: 0.7440, Val F1: 0.7440\n",
            "Epoch: 007, Train Acc: 0.9571, Train F1: 0.9571, Val Acc: 0.7600, Val F1: 0.7600\n",
            "Epoch: 008, Train Acc: 0.9714, Train F1: 0.9714, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 009, Train Acc: 0.9714, Train F1: 0.9714, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 010, Train Acc: 0.9714, Train F1: 0.9714, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 011, Train Acc: 0.9714, Train F1: 0.9714, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 012, Train Acc: 0.9714, Train F1: 0.9714, Val Acc: 0.7800, Val F1: 0.7800\n",
            "Epoch: 013, Train Acc: 0.9786, Train F1: 0.9786, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 014, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 015, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 016, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 017, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 018, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 019, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 020, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 021, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 022, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 023, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 024, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 025, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 026, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 027, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 028, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 029, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 030, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 031, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 032, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 033, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 034, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 035, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 036, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 037, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 038, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 039, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 040, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 041, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 042, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 043, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 044, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 045, Train Acc: 0.9857, Train F1: 0.9857, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 046, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 047, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 048, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7960, Val F1: 0.7960\n",
            "Epoch: 049, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 050, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 051, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 052, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 053, Train Acc: 0.9929, Train F1: 0.9929, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 054, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 055, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 056, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 057, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 058, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 059, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 060, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 061, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 062, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 063, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 064, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 065, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 066, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 067, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7840, Val F1: 0.7840\n",
            "Epoch: 068, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 069, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 070, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 071, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 072, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 073, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 074, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 075, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 076, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 077, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 078, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 079, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 080, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 081, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 082, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 083, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 084, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 085, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7940, Val F1: 0.7940\n",
            "Epoch: 086, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 087, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 088, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 089, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7920, Val F1: 0.7920\n",
            "Epoch: 090, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7900, Val F1: 0.7900\n",
            "Epoch: 091, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 092, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7880, Val F1: 0.7880\n",
            "Epoch: 093, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7860, Val F1: 0.7860\n",
            "Epoch: 094, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 095, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Epoch: 096, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 097, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7760, Val F1: 0.7760\n",
            "Epoch: 098, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 099, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7780, Val F1: 0.7780\n",
            "Epoch: 100, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.7820, Val F1: 0.7820\n",
            "Current GPU memory: 81.64 MB\n",
            "Max GPU memory used: 90.93 MB\n",
            "Time taken: 4.81 seconds\n",
            "Embeddings: 0.2 MB, Weights: 0.0 MB, Total: 0.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Citeseer dataset**"
      ],
      "metadata": {
        "id": "KCY-fcpYFVUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())\n",
        "num_features = dataset.num_features\n",
        "num_classes = dataset.num_classes\n",
        "data = dataset[0].to(device)  # Get the first graph object.\n",
        "data\n",
        "print(f'Number of nodes:          {data.num_nodes}')\n",
        "print(f'Number of edges:          {data.num_edges}')\n",
        "print(f'Average node degree:      {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
        "print(f'Has isolated nodes:       {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops:           {data.has_self_loops()}')\n",
        "print(f'Is undirected:            {data.is_undirected()}')\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_features, 64, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train(data, data.train_mask)\n",
        "    train_acc, train_f1 = test(data, data.train_mask)\n",
        "    val_acc, val_f1 = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "test_acc,f1_micro = test(data, data.test_mask)\n",
        "test_acc\n",
        "\n",
        "out = model(data.x, data.edge_index)\n",
        "e, w, t = gcn_memory_usage(2, data.num_nodes, out.shape[1])\n",
        "print(f\"Embeddings: {e/1e6:.1f} MB, Weights: {w*4/1e6:.1f} MB, Total: {t/1e6:.1f} MB\")\n",
        "\n",
        "\n",
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"GCN full-batch\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"embedding_storage\":e,\n",
        "    \"Weight_Matrices\":w,\n",
        "    \"Total_Memory\":t\n",
        "}\n",
        "\n",
        "with open(\"GCN_full_batch_citeseer_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "Wbi7f8EBFi9s",
        "outputId": "6d767805-c397-449a-e888-5789df30457c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 73.46 MB\n",
            "Using device: cuda\n",
            "Number of nodes:          3327\n",
            "Number of edges:          9104\n",
            "Average node degree:      2.74\n",
            "Number of training nodes: 120\n",
            "Training node label rate: 0.036\n",
            "Has isolated nodes:       True\n",
            "Has self-loops:           False\n",
            "Is undirected:            True\n",
            "Epoch: 001, Train Acc: 0.6167, Train F1: 0.6167, Val Acc: 0.3340, Val F1: 0.3340\n",
            "Epoch: 002, Train Acc: 0.8167, Train F1: 0.8167, Val Acc: 0.4100, Val F1: 0.4100\n",
            "Epoch: 003, Train Acc: 0.8667, Train F1: 0.8667, Val Acc: 0.3980, Val F1: 0.3980\n",
            "Epoch: 004, Train Acc: 0.9167, Train F1: 0.9167, Val Acc: 0.4180, Val F1: 0.4180\n",
            "Epoch: 005, Train Acc: 0.8917, Train F1: 0.8917, Val Acc: 0.4480, Val F1: 0.4480\n",
            "Epoch: 006, Train Acc: 0.9083, Train F1: 0.9083, Val Acc: 0.4900, Val F1: 0.4900\n",
            "Epoch: 007, Train Acc: 0.9250, Train F1: 0.9250, Val Acc: 0.5360, Val F1: 0.5360\n",
            "Epoch: 008, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.5480, Val F1: 0.5480\n",
            "Epoch: 009, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.5660, Val F1: 0.5660\n",
            "Epoch: 010, Train Acc: 0.9417, Train F1: 0.9417, Val Acc: 0.5680, Val F1: 0.5680\n",
            "Epoch: 011, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.5940, Val F1: 0.5940\n",
            "Epoch: 012, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.6200, Val F1: 0.6200\n",
            "Epoch: 013, Train Acc: 0.9333, Train F1: 0.9333, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 014, Train Acc: 0.9417, Train F1: 0.9417, Val Acc: 0.6640, Val F1: 0.6640\n",
            "Epoch: 015, Train Acc: 0.9417, Train F1: 0.9417, Val Acc: 0.6780, Val F1: 0.6780\n",
            "Epoch: 016, Train Acc: 0.9417, Train F1: 0.9417, Val Acc: 0.6800, Val F1: 0.6800\n",
            "Epoch: 017, Train Acc: 0.9417, Train F1: 0.9417, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 018, Train Acc: 0.9500, Train F1: 0.9500, Val Acc: 0.6900, Val F1: 0.6900\n",
            "Epoch: 019, Train Acc: 0.9583, Train F1: 0.9583, Val Acc: 0.6900, Val F1: 0.6900\n",
            "Epoch: 020, Train Acc: 0.9583, Train F1: 0.9583, Val Acc: 0.6920, Val F1: 0.6920\n",
            "Epoch: 021, Train Acc: 0.9583, Train F1: 0.9583, Val Acc: 0.6920, Val F1: 0.6920\n",
            "Epoch: 022, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6920, Val F1: 0.6920\n",
            "Epoch: 023, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6920, Val F1: 0.6920\n",
            "Epoch: 024, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6900, Val F1: 0.6900\n",
            "Epoch: 025, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6920, Val F1: 0.6920\n",
            "Epoch: 026, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6940, Val F1: 0.6940\n",
            "Epoch: 027, Train Acc: 0.9667, Train F1: 0.9667, Val Acc: 0.6960, Val F1: 0.6960\n",
            "Epoch: 028, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6960, Val F1: 0.6960\n",
            "Epoch: 029, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6980, Val F1: 0.6980\n",
            "Epoch: 030, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6980, Val F1: 0.6980\n",
            "Epoch: 031, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6940, Val F1: 0.6940\n",
            "Epoch: 032, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6940, Val F1: 0.6940\n",
            "Epoch: 033, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6940, Val F1: 0.6940\n",
            "Epoch: 034, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6960, Val F1: 0.6960\n",
            "Epoch: 035, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.7020, Val F1: 0.7020\n",
            "Epoch: 036, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.7020, Val F1: 0.7020\n",
            "Epoch: 037, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6980, Val F1: 0.6980\n",
            "Epoch: 038, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6960, Val F1: 0.6960\n",
            "Epoch: 039, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6940, Val F1: 0.6940\n",
            "Epoch: 040, Train Acc: 0.9750, Train F1: 0.9750, Val Acc: 0.6960, Val F1: 0.6960\n",
            "Epoch: 041, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.6900, Val F1: 0.6900\n",
            "Epoch: 042, Train Acc: 0.9833, Train F1: 0.9833, Val Acc: 0.6820, Val F1: 0.6820\n",
            "Epoch: 043, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6860, Val F1: 0.6860\n",
            "Epoch: 044, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6900, Val F1: 0.6900\n",
            "Epoch: 045, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 046, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 047, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6840, Val F1: 0.6840\n",
            "Epoch: 048, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 049, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6880, Val F1: 0.6880\n",
            "Epoch: 050, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6840, Val F1: 0.6840\n",
            "Epoch: 051, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6780, Val F1: 0.6780\n",
            "Epoch: 052, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6760, Val F1: 0.6760\n",
            "Epoch: 053, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6740, Val F1: 0.6740\n",
            "Epoch: 054, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6700, Val F1: 0.6700\n",
            "Epoch: 055, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6660, Val F1: 0.6660\n",
            "Epoch: 056, Train Acc: 0.9917, Train F1: 0.9917, Val Acc: 0.6660, Val F1: 0.6660\n",
            "Epoch: 057, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6640, Val F1: 0.6640\n",
            "Epoch: 058, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6620, Val F1: 0.6620\n",
            "Epoch: 059, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 060, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6600, Val F1: 0.6600\n",
            "Epoch: 061, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6560, Val F1: 0.6560\n",
            "Epoch: 062, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 063, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 064, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 065, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6620, Val F1: 0.6620\n",
            "Epoch: 066, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6640, Val F1: 0.6640\n",
            "Epoch: 067, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6620, Val F1: 0.6620\n",
            "Epoch: 068, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 069, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 070, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 071, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6580, Val F1: 0.6580\n",
            "Epoch: 072, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6540, Val F1: 0.6540\n",
            "Epoch: 073, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6540, Val F1: 0.6540\n",
            "Epoch: 074, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6560, Val F1: 0.6560\n",
            "Epoch: 075, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6560, Val F1: 0.6560\n",
            "Epoch: 076, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6540, Val F1: 0.6540\n",
            "Epoch: 077, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 078, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 079, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 080, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 081, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 082, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 083, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 084, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 085, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 086, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6460, Val F1: 0.6460\n",
            "Epoch: 087, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6440, Val F1: 0.6440\n",
            "Epoch: 088, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6440, Val F1: 0.6440\n",
            "Epoch: 089, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6440, Val F1: 0.6440\n",
            "Epoch: 090, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6480, Val F1: 0.6480\n",
            "Epoch: 091, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6480, Val F1: 0.6480\n",
            "Epoch: 092, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6440, Val F1: 0.6440\n",
            "Epoch: 093, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6480, Val F1: 0.6480\n",
            "Epoch: 094, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 095, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6560, Val F1: 0.6560\n",
            "Epoch: 096, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6520, Val F1: 0.6520\n",
            "Epoch: 097, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 098, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 099, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Epoch: 100, Train Acc: 1.0000, Train F1: 1.0000, Val Acc: 0.6500, Val F1: 0.6500\n",
            "Current GPU memory: 123.36 MB\n",
            "Max GPU memory used: 132.19 MB\n",
            "Time taken: 2.12 seconds\n",
            "Embeddings: 0.2 MB, Weights: 0.0 MB, Total: 0.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amazon dataset**"
      ],
      "metadata": {
        "id": "O86zR-LAL7O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "dataset = Amazon(\n",
        "        root='data/Amazon',\n",
        "        name='Computers',\n",
        "        transform=T.Compose([\n",
        "        NormalizeFeatures(),          # feature‑wise ℓ₂ normalisation\n",
        "        RandomNodeSplit(              # ⇦ add a split transform\n",
        "                split='train_rest',       # 10% val, 10% test by default\n",
        "                num_val=0.1,\n",
        "                num_test=0.1,\n",
        "                num_splits=1,\n",
        "            )\n",
        "        ])\n",
        "    )\n",
        "num_features = dataset.num_features\n",
        "num_classes = dataset.num_classes\n",
        "data = dataset[0].to(device)  # Get the first graph object.\n",
        "data\n",
        "print(f'Number of nodes:          {data.num_nodes}')\n",
        "print(f'Number of edges:          {data.num_edges}')\n",
        "print(f'Average node degree:      {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
        "print(f'Has isolated nodes:       {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops:           {data.has_self_loops()}')\n",
        "print(f'Is undirected:            {data.is_undirected()}')\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_features, 64, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train(data, data.train_mask)\n",
        "    train_acc, train_f1 = test(data, data.train_mask)\n",
        "    val_acc, val_f1 = test(data, data.val_mask)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "test_acc,f1_micro = test(data, data.test_mask)\n",
        "test_acc\n",
        "\n",
        "out = model(data.x, data.edge_index)\n",
        "e, w, t = gcn_memory_usage(2, data.num_nodes, out.shape[1])\n",
        "print(f\"Embeddings: {e/1e6:.1f} MB, Weights: {w*4/1e6:.1f} MB, Total: {t/1e6:.1f} MB\")\n",
        "\n",
        "\n",
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"GCN full-batch\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"embedding_storage\":e,\n",
        "    \"Weight_Matrices\":w,\n",
        "    \"Total_Memory\":t\n",
        "}\n",
        "\n",
        "with open(\"GCN_full_batch_Amazon_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "crw4u9MFL-N5",
        "outputId": "f0a1a795-d888-40f3-b094-af861a56b10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 107.97 MB\n",
            "Using device: cuda\n",
            "Number of nodes:          13752\n",
            "Number of edges:          491722\n",
            "Average node degree:      35.76\n",
            "Number of training nodes: 11002\n",
            "Training node label rate: 0.800\n",
            "Has isolated nodes:       True\n",
            "Has self-loops:           False\n",
            "Is undirected:            True\n",
            "Epoch: 001, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 002, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 003, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 004, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 005, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 006, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 007, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 008, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 009, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 010, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 011, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 012, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 013, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 014, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 015, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 016, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 017, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 018, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 019, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 020, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 021, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 022, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 023, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 024, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 025, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 026, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 027, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 028, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 029, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 030, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 031, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 032, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 033, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 034, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 035, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 036, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 037, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 038, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 039, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 040, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 041, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 042, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 043, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 044, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 045, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 046, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 047, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 048, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 049, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 050, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 051, Train Acc: 0.3739, Train F1: 0.3739, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 052, Train Acc: 0.3739, Train F1: 0.3739, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 053, Train Acc: 0.3738, Train F1: 0.3738, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 054, Train Acc: 0.3742, Train F1: 0.3742, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 055, Train Acc: 0.3743, Train F1: 0.3743, Val Acc: 0.3724, Val F1: 0.3724\n",
            "Epoch: 056, Train Acc: 0.3750, Train F1: 0.3750, Val Acc: 0.3731, Val F1: 0.3731\n",
            "Epoch: 057, Train Acc: 0.3776, Train F1: 0.3776, Val Acc: 0.3753, Val F1: 0.3753\n",
            "Epoch: 058, Train Acc: 0.3821, Train F1: 0.3821, Val Acc: 0.3767, Val F1: 0.3767\n",
            "Epoch: 059, Train Acc: 0.3861, Train F1: 0.3861, Val Acc: 0.3840, Val F1: 0.3840\n",
            "Epoch: 060, Train Acc: 0.3916, Train F1: 0.3916, Val Acc: 0.3920, Val F1: 0.3920\n",
            "Epoch: 061, Train Acc: 0.3951, Train F1: 0.3951, Val Acc: 0.4000, Val F1: 0.4000\n",
            "Epoch: 062, Train Acc: 0.4006, Train F1: 0.4006, Val Acc: 0.4065, Val F1: 0.4065\n",
            "Epoch: 063, Train Acc: 0.4055, Train F1: 0.4055, Val Acc: 0.4124, Val F1: 0.4124\n",
            "Epoch: 064, Train Acc: 0.4098, Train F1: 0.4098, Val Acc: 0.4175, Val F1: 0.4175\n",
            "Epoch: 065, Train Acc: 0.4141, Train F1: 0.4141, Val Acc: 0.4240, Val F1: 0.4240\n",
            "Epoch: 066, Train Acc: 0.4186, Train F1: 0.4186, Val Acc: 0.4298, Val F1: 0.4298\n",
            "Epoch: 067, Train Acc: 0.4242, Train F1: 0.4242, Val Acc: 0.4378, Val F1: 0.4378\n",
            "Epoch: 068, Train Acc: 0.4327, Train F1: 0.4327, Val Acc: 0.4516, Val F1: 0.4516\n",
            "Epoch: 069, Train Acc: 0.4436, Train F1: 0.4436, Val Acc: 0.4596, Val F1: 0.4596\n",
            "Epoch: 070, Train Acc: 0.4576, Train F1: 0.4576, Val Acc: 0.4727, Val F1: 0.4727\n",
            "Epoch: 071, Train Acc: 0.4674, Train F1: 0.4674, Val Acc: 0.4800, Val F1: 0.4800\n",
            "Epoch: 072, Train Acc: 0.4771, Train F1: 0.4771, Val Acc: 0.4902, Val F1: 0.4902\n",
            "Epoch: 073, Train Acc: 0.4859, Train F1: 0.4859, Val Acc: 0.4953, Val F1: 0.4953\n",
            "Epoch: 074, Train Acc: 0.4923, Train F1: 0.4923, Val Acc: 0.5004, Val F1: 0.5004\n",
            "Epoch: 075, Train Acc: 0.4995, Train F1: 0.4995, Val Acc: 0.5098, Val F1: 0.5098\n",
            "Epoch: 076, Train Acc: 0.5082, Train F1: 0.5082, Val Acc: 0.5149, Val F1: 0.5149\n",
            "Epoch: 077, Train Acc: 0.5200, Train F1: 0.5200, Val Acc: 0.5265, Val F1: 0.5265\n",
            "Epoch: 078, Train Acc: 0.5327, Train F1: 0.5327, Val Acc: 0.5316, Val F1: 0.5316\n",
            "Epoch: 079, Train Acc: 0.5464, Train F1: 0.5464, Val Acc: 0.5418, Val F1: 0.5418\n",
            "Epoch: 080, Train Acc: 0.5568, Train F1: 0.5568, Val Acc: 0.5513, Val F1: 0.5513\n",
            "Epoch: 081, Train Acc: 0.5679, Train F1: 0.5679, Val Acc: 0.5665, Val F1: 0.5665\n",
            "Epoch: 082, Train Acc: 0.5774, Train F1: 0.5774, Val Acc: 0.5745, Val F1: 0.5745\n",
            "Epoch: 083, Train Acc: 0.5859, Train F1: 0.5859, Val Acc: 0.5833, Val F1: 0.5833\n",
            "Epoch: 084, Train Acc: 0.5923, Train F1: 0.5923, Val Acc: 0.5862, Val F1: 0.5862\n",
            "Epoch: 085, Train Acc: 0.5963, Train F1: 0.5963, Val Acc: 0.5891, Val F1: 0.5891\n",
            "Epoch: 086, Train Acc: 0.6035, Train F1: 0.6035, Val Acc: 0.5920, Val F1: 0.5920\n",
            "Epoch: 087, Train Acc: 0.6107, Train F1: 0.6107, Val Acc: 0.6022, Val F1: 0.6022\n",
            "Epoch: 088, Train Acc: 0.6177, Train F1: 0.6177, Val Acc: 0.6095, Val F1: 0.6095\n",
            "Epoch: 089, Train Acc: 0.6224, Train F1: 0.6224, Val Acc: 0.6131, Val F1: 0.6131\n",
            "Epoch: 090, Train Acc: 0.6251, Train F1: 0.6251, Val Acc: 0.6189, Val F1: 0.6189\n",
            "Epoch: 091, Train Acc: 0.6280, Train F1: 0.6280, Val Acc: 0.6196, Val F1: 0.6196\n",
            "Epoch: 092, Train Acc: 0.6308, Train F1: 0.6308, Val Acc: 0.6240, Val F1: 0.6240\n",
            "Epoch: 093, Train Acc: 0.6346, Train F1: 0.6346, Val Acc: 0.6291, Val F1: 0.6291\n",
            "Epoch: 094, Train Acc: 0.6378, Train F1: 0.6378, Val Acc: 0.6335, Val F1: 0.6335\n",
            "Epoch: 095, Train Acc: 0.6406, Train F1: 0.6406, Val Acc: 0.6349, Val F1: 0.6349\n",
            "Epoch: 096, Train Acc: 0.6450, Train F1: 0.6450, Val Acc: 0.6371, Val F1: 0.6371\n",
            "Epoch: 097, Train Acc: 0.6452, Train F1: 0.6452, Val Acc: 0.6378, Val F1: 0.6378\n",
            "Epoch: 098, Train Acc: 0.6460, Train F1: 0.6460, Val Acc: 0.6393, Val F1: 0.6393\n",
            "Epoch: 099, Train Acc: 0.6477, Train F1: 0.6477, Val Acc: 0.6393, Val F1: 0.6393\n",
            "Epoch: 100, Train Acc: 0.6488, Train F1: 0.6488, Val Acc: 0.6407, Val F1: 0.6407\n",
            "Current GPU memory: 154.95 MB\n",
            "Max GPU memory used: 421.30 MB\n",
            "Time taken: 3.97 seconds\n",
            "Embeddings: 1.1 MB, Weights: 0.0 MB, Total: 1.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(data.x, data.edge_index)\n",
        "print(out.shape[1])\n"
      ],
      "metadata": {
        "id": "Wo0QoyJBfzul",
        "outputId": "6b0fe7d6-08b5-4b6b-a018-5060a52affcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    }
  ]
}