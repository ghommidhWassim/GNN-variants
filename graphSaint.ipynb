{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/graphSaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install torchvision\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MxXKQdoYf_",
        "outputId": "bacdc682-c60a-4689-c1f3-d11a6f6c3bfe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "2.6.0+cu124\n",
            "12.4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt26cu124)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ruzytV_Nk9LG"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio --quiet\n",
        "# !pip install scipy numpy --quiet\n",
        "# !git clone https://github.com/graphsaint/graphsaint.git  # if you want to use official repo, or upload your own files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import time\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import GraphSAINTNodeSampler, GraphSAINTEdgeSampler, GraphSAINTRandomWalkSampler\n",
        "\n",
        "# (You will have to upload or place the GraphSAINT modules or install them if available)\n",
        "# For simplicity, assume graphsaint package is already in your environment or uploaded as files.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqMSSoVJ0rXT",
        "outputId": "cec6ae3f-7998-4700-f666-a6192d3bdeaa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJTVRr2c_kYA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.cpu()\n",
        "loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "#loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "#loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=500, walk_length=2, num_steps=4, sample_coverage=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhQYYlP5t8K",
        "outputId": "c06e8178-deff-4c06-830d-ed3088411617"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 198778it [00:00, 927460.84it/s]                          \n",
            "Compute GraphSAINT normalization: : 198592it [03:03, 1085.04it/s]                          \n",
            "Compute GraphSAINT normalization: : 197445it [00:00, 2301321.51it/s]        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, edge_weight=None):\n",
        "      x = self.conv1(x, edge_index, edge_weight)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=0.5, training=self.training)\n",
        "      x = self.conv2(x, edge_index, edge_weight)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "q75oq00V834G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "csFgXNhR_A7-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_norm)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# ------------------- Evaluation Function -------------------\n",
        "@torch.no_grad()\n",
        "def test(model, full_data):\n",
        "    model.eval()\n",
        "    out = model(full_data.x.to(device), full_data.edge_index.to(device))\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct = (pred[full_data.test_mask] == full_data.y[full_data.test_mask].to(device)).sum()\n",
        "    acc = int(correct) / int(full_data.test_mask.sum())\n",
        "    return acc\n",
        "\n",
        "# ------------------- Run Training -------------------\n",
        "def run(loader, method_name):\n",
        "    # Use the global num_classes variable instead of trying to access it from the data object\n",
        "\n",
        "\n",
        "    for epoch in range(1, 101):\n",
        "        loss = train(model, loader, optimizer, criterion)\n",
        "        print(f'{method_name} | Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    acc = test(model, data)\n",
        "    print(f'{method_name} | Final Test Accuracy: {acc:.4f}')\n",
        "\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "#run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "#run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSiTzZo9Aaf",
        "outputId": "d5c45599-3ccb-470f-87fe-e59fcc975bbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAINT-NodeSampler | Epoch 001, Loss: 1.0787\n",
            "GraphSAINT-NodeSampler | Epoch 002, Loss: 1.0382\n",
            "GraphSAINT-NodeSampler | Epoch 003, Loss: 0.9872\n",
            "GraphSAINT-NodeSampler | Epoch 004, Loss: 0.9641\n",
            "GraphSAINT-NodeSampler | Epoch 005, Loss: 0.9311\n",
            "GraphSAINT-NodeSampler | Epoch 006, Loss: 0.8944\n",
            "GraphSAINT-NodeSampler | Epoch 007, Loss: 0.8861\n",
            "GraphSAINT-NodeSampler | Epoch 008, Loss: 0.8129\n",
            "GraphSAINT-NodeSampler | Epoch 009, Loss: 0.8066\n",
            "GraphSAINT-NodeSampler | Epoch 010, Loss: 0.7673\n",
            "GraphSAINT-NodeSampler | Epoch 011, Loss: 0.7819\n",
            "GraphSAINT-NodeSampler | Epoch 012, Loss: 0.7112\n",
            "GraphSAINT-NodeSampler | Epoch 013, Loss: 0.7072\n",
            "GraphSAINT-NodeSampler | Epoch 014, Loss: 0.6696\n",
            "GraphSAINT-NodeSampler | Epoch 015, Loss: 0.6554\n",
            "GraphSAINT-NodeSampler | Epoch 016, Loss: 0.6377\n",
            "GraphSAINT-NodeSampler | Epoch 017, Loss: 0.6181\n",
            "GraphSAINT-NodeSampler | Epoch 018, Loss: 0.5968\n",
            "GraphSAINT-NodeSampler | Epoch 019, Loss: 0.6515\n",
            "GraphSAINT-NodeSampler | Epoch 020, Loss: 0.5709\n",
            "GraphSAINT-NodeSampler | Epoch 021, Loss: 0.6019\n",
            "GraphSAINT-NodeSampler | Epoch 022, Loss: 0.5656\n",
            "GraphSAINT-NodeSampler | Epoch 023, Loss: 0.6714\n",
            "GraphSAINT-NodeSampler | Epoch 024, Loss: 0.5573\n",
            "GraphSAINT-NodeSampler | Epoch 025, Loss: 0.5683\n",
            "GraphSAINT-NodeSampler | Epoch 026, Loss: 0.5450\n",
            "GraphSAINT-NodeSampler | Epoch 027, Loss: 0.5332\n",
            "GraphSAINT-NodeSampler | Epoch 028, Loss: 0.5325\n",
            "GraphSAINT-NodeSampler | Epoch 029, Loss: 0.5103\n",
            "GraphSAINT-NodeSampler | Epoch 030, Loss: 0.5956\n",
            "GraphSAINT-NodeSampler | Epoch 031, Loss: 0.5474\n",
            "GraphSAINT-NodeSampler | Epoch 032, Loss: 0.6599\n",
            "GraphSAINT-NodeSampler | Epoch 033, Loss: 0.5046\n",
            "GraphSAINT-NodeSampler | Epoch 034, Loss: 0.5395\n",
            "GraphSAINT-NodeSampler | Epoch 035, Loss: 0.5251\n",
            "GraphSAINT-NodeSampler | Epoch 036, Loss: 0.4983\n",
            "GraphSAINT-NodeSampler | Epoch 037, Loss: 0.5214\n",
            "GraphSAINT-NodeSampler | Epoch 038, Loss: 0.4932\n",
            "GraphSAINT-NodeSampler | Epoch 039, Loss: 0.4979\n",
            "GraphSAINT-NodeSampler | Epoch 040, Loss: 0.4968\n",
            "GraphSAINT-NodeSampler | Epoch 041, Loss: 0.5134\n",
            "GraphSAINT-NodeSampler | Epoch 042, Loss: 0.4609\n",
            "GraphSAINT-NodeSampler | Epoch 043, Loss: 0.4809\n",
            "GraphSAINT-NodeSampler | Epoch 044, Loss: 0.5076\n",
            "GraphSAINT-NodeSampler | Epoch 045, Loss: 0.4717\n",
            "GraphSAINT-NodeSampler | Epoch 046, Loss: 0.4834\n",
            "GraphSAINT-NodeSampler | Epoch 047, Loss: 0.4485\n",
            "GraphSAINT-NodeSampler | Epoch 048, Loss: 0.5239\n",
            "GraphSAINT-NodeSampler | Epoch 049, Loss: 0.4969\n",
            "GraphSAINT-NodeSampler | Epoch 050, Loss: 0.4693\n",
            "GraphSAINT-NodeSampler | Epoch 051, Loss: 0.5260\n",
            "GraphSAINT-NodeSampler | Epoch 052, Loss: 0.4734\n",
            "GraphSAINT-NodeSampler | Epoch 053, Loss: 0.4780\n",
            "GraphSAINT-NodeSampler | Epoch 054, Loss: 0.4736\n",
            "GraphSAINT-NodeSampler | Epoch 055, Loss: 0.4679\n",
            "GraphSAINT-NodeSampler | Epoch 056, Loss: 0.4952\n",
            "GraphSAINT-NodeSampler | Epoch 057, Loss: 0.4712\n",
            "GraphSAINT-NodeSampler | Epoch 058, Loss: 0.4501\n",
            "GraphSAINT-NodeSampler | Epoch 059, Loss: 0.5757\n",
            "GraphSAINT-NodeSampler | Epoch 060, Loss: 0.4409\n",
            "GraphSAINT-NodeSampler | Epoch 061, Loss: 0.5084\n",
            "GraphSAINT-NodeSampler | Epoch 062, Loss: 0.5419\n",
            "GraphSAINT-NodeSampler | Epoch 063, Loss: 0.4812\n",
            "GraphSAINT-NodeSampler | Epoch 064, Loss: 0.4594\n",
            "GraphSAINT-NodeSampler | Epoch 065, Loss: 0.4638\n",
            "GraphSAINT-NodeSampler | Epoch 066, Loss: 0.4544\n",
            "GraphSAINT-NodeSampler | Epoch 067, Loss: 0.4310\n",
            "GraphSAINT-NodeSampler | Epoch 068, Loss: 0.4367\n",
            "GraphSAINT-NodeSampler | Epoch 069, Loss: 0.5400\n",
            "GraphSAINT-NodeSampler | Epoch 070, Loss: 0.4614\n",
            "GraphSAINT-NodeSampler | Epoch 071, Loss: 0.4450\n",
            "GraphSAINT-NodeSampler | Epoch 072, Loss: 0.4627\n",
            "GraphSAINT-NodeSampler | Epoch 073, Loss: 0.4734\n",
            "GraphSAINT-NodeSampler | Epoch 074, Loss: 0.4914\n",
            "GraphSAINT-NodeSampler | Epoch 075, Loss: 0.4480\n",
            "GraphSAINT-NodeSampler | Epoch 076, Loss: 0.4364\n",
            "GraphSAINT-NodeSampler | Epoch 077, Loss: 0.4460\n",
            "GraphSAINT-NodeSampler | Epoch 078, Loss: 0.4766\n",
            "GraphSAINT-NodeSampler | Epoch 079, Loss: 0.4513\n",
            "GraphSAINT-NodeSampler | Epoch 080, Loss: 0.4412\n",
            "GraphSAINT-NodeSampler | Epoch 081, Loss: 0.4464\n",
            "GraphSAINT-NodeSampler | Epoch 082, Loss: 0.4721\n",
            "GraphSAINT-NodeSampler | Epoch 083, Loss: 0.4462\n",
            "GraphSAINT-NodeSampler | Epoch 084, Loss: 0.4412\n",
            "GraphSAINT-NodeSampler | Epoch 085, Loss: 0.4434\n",
            "GraphSAINT-NodeSampler | Epoch 086, Loss: 0.4366\n",
            "GraphSAINT-NodeSampler | Epoch 087, Loss: 0.4496\n",
            "GraphSAINT-NodeSampler | Epoch 088, Loss: 0.4635\n",
            "GraphSAINT-NodeSampler | Epoch 089, Loss: 0.5059\n",
            "GraphSAINT-NodeSampler | Epoch 090, Loss: 0.4189\n",
            "GraphSAINT-NodeSampler | Epoch 091, Loss: 0.4433\n",
            "GraphSAINT-NodeSampler | Epoch 092, Loss: 0.4390\n",
            "GraphSAINT-NodeSampler | Epoch 093, Loss: 0.6115\n",
            "GraphSAINT-NodeSampler | Epoch 094, Loss: 0.4126\n",
            "GraphSAINT-NodeSampler | Epoch 095, Loss: 0.4848\n",
            "GraphSAINT-NodeSampler | Epoch 096, Loss: 0.4135\n",
            "GraphSAINT-NodeSampler | Epoch 097, Loss: 0.4273\n",
            "GraphSAINT-NodeSampler | Epoch 098, Loss: 0.4314\n",
            "GraphSAINT-NodeSampler | Epoch 099, Loss: 0.4269\n",
            "GraphSAINT-NodeSampler | Epoch 100, Loss: 0.4300\n",
            "GraphSAINT-NodeSampler | Final Test Accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anderskm/gputil.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPUYqphbJk1E",
        "outputId": "7f6dd5cf-b57b-43c0-ef89-7c34bb985215"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gputil'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Total 456 (delta 0), reused 0 (delta 0), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 83.68 KiB | 11.95 MiB/s, done.\n",
            "Resolving deltas: 100% (263/263), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gputil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAtqzeViJsuR",
        "outputId": "e23b1c1a-7b46-4f87-8a3b-5d7f43913356"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=9603a18d140bc2e9b368d954f7252290f84ee7eeba5f271547fa5c2bd54ccb15\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GPUtil\n",
        "GPUtil.showUtilization()\n",
        "GPUs = GPUtil.getGPUs()\n",
        "GPUs[0].memoryUsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbLB_-TnJ-0R",
        "outputId": "e36e1e98-d2e4-466e-e0dc-dd99ae4e289a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  1% |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "218.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used:  {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "XOWkhJt4OEC3",
        "outputId": "723aef7b-fc72-4f55-eaf1-8e34a967c97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated: 16.38 MB\n",
            "Max GPU memory used:  73.44 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total reserved memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
        "print(f\"Max reserved memory:   {torch.cuda.max_memory_reserved() / 1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "hbbsvfZ2M8Cu",
        "outputId": "973fc1c2-3c5e-415b-cdd6-35dd4ccab204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reserved memory: 82.00 MB\n",
            "Max reserved memory:   82.00 MB\n"
          ]
        }
      ]
    }
  ]
}