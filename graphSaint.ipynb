{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/graphSaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install torchvision\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MxXKQdoYf_",
        "outputId": "ce44816e-74f3-4c7b-f776-dfd27c685ccd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "2.6.0+cu124\n",
            "12.4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ruzytV_Nk9LG"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio --quiet\n",
        "# !pip install scipy numpy --quiet\n",
        "# !git clone https://github.com/graphsaint/graphsaint.git  # if you want to use official repo, or upload your own files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import time\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.datasets import Planetoid, Amazon\n",
        "from torch_geometric.transforms import NormalizeFeatures, RandomNodeSplit\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import GraphSAINTNodeSampler, GraphSAINTEdgeSampler, GraphSAINTRandomWalkSampler\n",
        "from sklearn.metrics import f1_score       # add this import once, near the top\n",
        "import torch.nn as nn\n",
        "import json\n",
        "# (You will have to upload or place the GraphSAINT modules or install them if available)\n",
        "# For simplicity, assume graphsaint package is already in your environment or uploaded as files.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "\n",
        "def clean_gpu_memory():\n",
        "    \"\"\"Cleans GPU memory without fully resetting the CUDA context\"\"\"\n",
        "    import gc\n",
        "    gc.collect()  # Python garbage collection\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # PyTorch cache\n",
        "        torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
        "        print(f\"Memory after cleanup: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "aqMSSoVJ0rXT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJTVRr2c_kYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhQYYlP5t8K",
        "outputId": "c06e8178-deff-4c06-830d-ed3088411617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 198778it [00:00, 927460.84it/s]                          \n",
            "Compute GraphSAINT normalization: : 198592it [03:03, 1085.04it/s]                          \n",
            "Compute GraphSAINT normalization: : 197445it [00:00, 2301321.51it/s]        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "q75oq00V834G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csFgXNhR_A7-",
        "outputId": "ad7506c0-a0ce-41ea-e937-d61144441b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-596637002.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-15-3487925365.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_channels)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_norm)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# ------------------- Evaluation Function -------------------\n",
        "@torch.no_grad()\n",
        "#def test(model, full_data):\n",
        " #   model.eval()\n",
        "  #  out = model(full_data.x.to(device), full_data.edge_index.to(device))\n",
        "  #  pred = out.argmax(dim=1)\n",
        "  #  correct = (pred[full_data.test_mask] == full_data.y[full_data.test_mask].to(device)).sum()\n",
        "  #  acc = int(correct) / int(full_data.test_mask.sum())\n",
        "   # return acc\n",
        "\n",
        "def test(model, full_data):\n",
        "    model.eval()\n",
        "    out = model(full_data.x.to(device), full_data.edge_index.to(device))\n",
        "\n",
        "    # predictions for every node\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    # isolate test nodes (keep everything on the SAME device, then move to CPU once)\n",
        "    test_mask = full_data.test_mask\n",
        "    y_true = full_data.y[test_mask].cpu()\n",
        "    y_pred = pred[test_mask].cpu()\n",
        "\n",
        "    # accuracy\n",
        "    acc = (y_pred == y_true).float().mean().item()\n",
        "\n",
        "    # micro‑F1\n",
        "    f1_micro = f1_score(y_true.numpy(), y_pred.numpy(), average='micro')\n",
        "\n",
        "    return acc, f1_micro\n",
        "# ------------------- Run Training -------------------\n",
        "def run(loader, method_name):\n",
        "    # Use the global num_classes variable instead of trying to access it from the data object\n",
        "\n",
        "\n",
        "    for epoch in range(1, 101):\n",
        "        loss = train(model, loader, optimizer, criterion)\n",
        "        print(f'{method_name} | Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    acc,test_f1 = test(model, data)\n",
        "    print(f'{method_name} | Final Test Accuracy: {acc:.4f} | Test F1 (micro): {test_f1:.4f}\")')\n",
        "    return acc,test_f1\n",
        "\n"
      ],
      "metadata": {
        "id": "rXSiTzZo9Aaf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "data = data.cpu()\n",
        "#loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "\n",
        "#loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "\n",
        "loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=2, num_steps=4, sample_coverage=10)\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "model = GCN(\n",
        "        in_channels=num_features,\n",
        "        hidden_channels=64,\n",
        "        out_channels=num_classes\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "\n",
        "#run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "\n",
        "#run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "start_time = time.time()\n",
        "\n",
        "test_acc,f1_micro =  run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n",
        "end_time = time.time()\n"
      ],
      "metadata": {
        "id": "vaTz1kcJKacD",
        "outputId": "081d84c3-c81a-44e2-a680-497ba600b31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 32.35 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 197171it [00:00, 700366.12it/s]                          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory: 32.35 MB\n",
            "Max GPU memory used: 71.91 MB\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.0769\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.0295\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.0015\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 0.9710\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 0.9126\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 0.8690\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 0.8127\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 0.8003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 0.7396\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 0.7762\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 0.6972\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 0.6855\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 0.6769\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 0.6255\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 0.6379\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 0.6497\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 0.6833\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 0.5879\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 0.6022\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 0.5968\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 0.5898\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 0.6219\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 0.5822\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 0.5843\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 0.5983\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 0.5959\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 0.5609\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 0.5386\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 0.5546\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 0.5451\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 0.5349\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 0.6471\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 0.5891\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 0.6013\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 0.5511\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 0.5566\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 0.6948\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 0.5622\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 0.5720\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 0.5345\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 0.5716\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 0.5468\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 0.5398\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 0.5657\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 0.5626\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 0.5371\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 0.5365\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 0.5510\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 0.5998\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 0.5132\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 0.5371\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 0.5453\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 0.5813\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 0.5278\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 0.4926\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 0.5587\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 0.5178\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 0.5167\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 0.5138\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 0.5164\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 0.5272\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 0.5805\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 0.5380\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 0.5138\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 0.5072\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 0.5158\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 0.4916\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 0.5152\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 0.5035\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 0.5157\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 0.5200\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 0.5464\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 0.5414\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 0.5148\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 0.5958\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 0.5187\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 0.5192\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 0.5085\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 0.5687\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 0.4895\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 0.6994\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 0.5483\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 0.5295\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 0.5530\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 0.5167\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 0.5483\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 0.5385\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 0.5437\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 0.5928\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 0.6049\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 0.5172\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 0.5193\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 0.5307\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 0.5262\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 0.4974\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 0.5218\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 0.5229\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 0.5661\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 0.5654\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 0.5811\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.8630 | Test F1 (micro): 0.8630\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "QszHC7qEX3zc",
        "outputId": "3de38a82-5ae6-4abd-abdf-3b0981707b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory: 17.72 MB\n",
            "Max GPU memory used: 121.68 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"graphSAINT\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":71.91\n",
        "}\n",
        "\n",
        "with open(\"graphSAINT_rw_pubmed_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "buAZqY5HQgy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cora**"
      ],
      "metadata": {
        "id": "bvNoGPbzZGJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "data = data.cpu()\n",
        "#loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=128, num_steps=4, sample_coverage=10)\n",
        "\n",
        "#loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "\n",
        "loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=2, num_steps=4, sample_coverage=10)\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "model = GCN(\n",
        "        in_channels=num_features,\n",
        "        hidden_channels=64,\n",
        "        out_channels=num_classes\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "\n",
        "#run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "#run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_acc,f1_micro =  run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n",
        "end_time = time.time()\n"
      ],
      "metadata": {
        "id": "Tj_VLh3yZIuL",
        "outputId": "b33b10e7-e336-431f-fd94-1b493d299c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 34.56 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 27920it [00:00, 754882.79it/s]         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory: 34.56 MB\n",
            "Max GPU memory used: 49.56 MB\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.9206\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.8519\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.7789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.7180\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.7123\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.6454\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5716\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.5109\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.4647\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.3780\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.3111\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.2841\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.2303\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.1116\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.0837\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.0886\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.0257\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 0.9950\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 0.9533\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 0.9064\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 0.9116\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 0.8535\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 0.8440\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 0.8477\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 0.8776\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 0.8327\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 0.8418\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 0.7248\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 0.7799\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 0.7627\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 0.7190\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 0.7234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 0.7114\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 0.7033\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 0.7195\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 0.6895\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 0.6839\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 0.6707\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 0.7014\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 0.6482\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 0.6964\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 0.6647\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 0.6501\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 0.6574\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 0.6515\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 0.6274\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 0.6166\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 0.6610\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 0.6073\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 0.6501\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 0.6075\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 0.6283\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 0.6257\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 0.5979\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 0.5866\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 0.6342\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 0.6338\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 0.5661\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 0.5968\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 0.5420\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 0.5832\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 0.5866\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 0.6087\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 0.5936\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 0.6051\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 0.5910\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 0.5782\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 0.5995\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 0.6125\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 0.5781\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 0.5875\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 0.5957\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 0.5603\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 0.5816\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 0.5635\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 0.5582\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 0.5813\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 0.5384\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 0.5849\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 0.6156\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 0.5710\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 0.5458\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 0.5817\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 0.5368\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 0.5926\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 0.5626\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 0.5531\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 0.5751\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 0.5752\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 0.5702\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 0.5275\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 0.5999\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 0.5470\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 0.5345\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 0.5594\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 0.5568\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 0.5159\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 0.5051\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 0.5692\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 0.5536\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.8980 | Test F1 (micro): 0.8980\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"graphSAINT\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":49.56\n",
        "}\n",
        "\n",
        "with open(\"graphSAINT_rw_Cora_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "Vlg9Z6_HZW_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cetiser**"
      ],
      "metadata": {
        "id": "MooX_bbnZJA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n",
        "data = data.cpu()\n",
        "#loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "\n",
        "#loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=128, num_steps=4, sample_coverage=10)\n",
        "\n",
        "loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=2, num_steps=4, sample_coverage=10)\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "model = GCN(\n",
        "        in_channels=num_features,\n",
        "        hidden_channels=64,\n",
        "        out_channels=num_classes\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "\n",
        "#run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "\n",
        "# run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_acc,f1_micro =  run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n",
        "end_time = time.time()\n"
      ],
      "metadata": {
        "id": "UrOXhWjHZMcz",
        "outputId": "df62b978-d640-4e8d-cb7f-ca83ee2228b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCompute GraphSAINT normalization:   0%|          | 0/137520 [14:05<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 30.94 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 34438it [00:00, 964641.18it/s]         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory: 30.94 MB\n",
            "Max GPU memory used: 78.11 MB\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.7738\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.7283\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.6956\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.6590\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.6234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.6000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5372\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.4884\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.4561\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4074\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.3485\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.2784\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.2542\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.2034\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.2021\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.1122\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.1206\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.1106\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 0.9980\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.0224\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 0.9916\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 0.9748\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 0.9389\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 0.9493\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 0.9627\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 0.8919\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 0.8579\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 0.8880\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 0.8989\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 0.8930\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 0.8320\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 0.8815\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 0.8330\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 0.8584\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 0.8232\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 0.8242\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 0.8267\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 0.8210\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 0.7855\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 0.7833\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 0.7663\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 0.8286\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 0.8401\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 0.8144\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 0.8018\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 0.7921\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 0.7843\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 0.7913\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 0.7835\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 0.7767\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 0.7784\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 0.8086\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 0.7589\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 0.7195\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 0.7479\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 0.7960\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 0.7697\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 0.7818\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 0.7898\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 0.7424\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 0.7806\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 0.7785\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 0.7206\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 0.7539\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 0.7582\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 0.7445\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 0.7775\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 0.7433\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 0.7331\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 0.7547\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 0.7398\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 0.7346\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 0.7399\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 0.6913\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 0.7403\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 0.7424\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 0.6995\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 0.7400\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 0.7099\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 0.7048\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 0.7036\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 0.6968\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 0.7188\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 0.7489\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 0.7515\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 0.6850\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 0.6761\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 0.7333\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 0.7222\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 0.7321\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 0.7423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 0.7160\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 0.7071\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 0.7058\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 0.7195\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 0.7513\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 0.7242\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 0.7376\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 0.7118\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 0.7239\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.8110 | Test F1 (micro): 0.8110\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"graphSAINT\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":78.11\n",
        "}\n",
        "\n",
        "with open(\"graphSAINT_rw_CiteSeer_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "Cl0uK9z8ah_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amazon**"
      ],
      "metadata": {
        "id": "EmIjpiz4ZM_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_gpu_memory()\n",
        "def dataset_load():\n",
        "  print(f\"Using device: {device}\")\n",
        "  dataset = Amazon(\n",
        "        root='data/Amazon',\n",
        "        name='Computers',\n",
        "        transform=T.Compose([\n",
        "        NormalizeFeatures(),          # feature‑wise ℓ₂ normalisation\n",
        "        RandomNodeSplit(              # ⇦ add a split transform\n",
        "                split='train_rest',       # 10% val, 10% test by default\n",
        "                num_val=0.1,\n",
        "                num_test=0.1,\n",
        "                num_splits=1,\n",
        "            )\n",
        "        ])\n",
        "    )\n",
        "  num_features = dataset.num_features\n",
        "  num_classes = dataset.num_classes\n",
        "  data = dataset[0].to(device)  # Get the first graph object.\n",
        "  return num_features, data, num_classes, device,dataset\n",
        "\n",
        "num_features, data, num_classes, device, dataset = dataset_load()\n",
        "data = data.cpu()\n",
        "#loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "\n",
        "#loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=128, num_steps=4, sample_coverage=10)\n",
        "\n",
        "loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=2, num_steps=4, sample_coverage=10)\n",
        "print(f\"Current GPU memory: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
        "model = GCN(\n",
        "        in_channels=num_features,\n",
        "        hidden_channels=64,\n",
        "        out_channels=num_classes\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "\n",
        "#run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "\n",
        "# run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "res=[]\n",
        "training=[]\n",
        "for i in range(10):\n",
        "  start_time = time.time()\n",
        "\n",
        "  test_acc,f1_micro = run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n",
        "  end_time = time.time()\n",
        "  res.append(test_acc)\n",
        "  training.append(end_time - start_time)"
      ],
      "metadata": {
        "id": "leKvNLO4dlfn",
        "outputId": "68720d34-473f-49bc-b9d2-455e25e4b21b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory after cleanup: 17.01 MB\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 138309it [00:00, 711678.76it/s]                         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU memory: 17.01 MB\n",
            "Max GPU memory used: 64.90 MB\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 2.2628\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 2.0962\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 2.0598\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.9924\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.8832\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.9479\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.9000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.9084\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.9198\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.9218\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.9010\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.8456\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.8747\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.9224\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 2.0195\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.8235\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.9108\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.8845\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.8435\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.9537\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.8965\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.9386\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.8588\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.8115\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.8675\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.9123\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.8588\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.8573\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.8872\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.9241\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.8523\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.8365\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.7934\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.8191\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.8546\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.8176\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.8402\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.8510\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.8751\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.8870\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.8236\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.8954\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.7556\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.9143\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.8056\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.8408\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.7751\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.7882\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.8064\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.8492\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.8552\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.7913\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.7977\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.7753\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.7832\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.8488\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.8126\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.7633\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.8820\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.8756\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.8423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.7956\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.8081\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.8039\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.7770\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.8386\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.8011\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.8536\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.7034\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.8327\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.8166\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.8047\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.7852\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.8405\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.8084\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.7789\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.7773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.7659\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.8027\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.8068\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.7562\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.7550\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.8248\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.8228\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.8154\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.7577\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.7707\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.7899\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.7645\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.8073\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.8387\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.7824\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.7696\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.7393\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.7276\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.7333\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.7618\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.7735\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.6937\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.7773\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.3673 | Test F1 (micro): 0.3673\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.6995\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.7696\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.7101\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.7068\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.7067\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.7154\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.7310\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.7105\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.6830\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.7772\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.7610\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.6559\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.6895\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.7499\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.8444\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.7086\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.7743\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.7502\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.6905\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.7176\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.8017\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.7218\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.7155\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.6952\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.7131\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.7215\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.6727\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.7065\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.7052\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.7588\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.6706\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.6982\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.6736\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.6751\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.7472\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.7400\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.7338\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.7293\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.7384\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.7120\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.6551\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.7182\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.7093\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.6880\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.7028\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.7095\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.6872\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.6556\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.6006\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.6725\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.6427\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.6492\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.7046\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.6842\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.6996\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.6533\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.6379\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.6090\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.6805\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.7055\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.7162\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.6815\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.6604\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.6105\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.6072\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.6325\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.6300\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.6490\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.6698\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.7670\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.6372\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5913\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.5982\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.6240\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.6245\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.6678\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.6687\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.6879\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.6461\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.6320\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.6554\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.6373\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.6583\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.6489\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.6562\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.6219\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.6435\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.6608\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.6631\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.6638\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.5833\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.7131\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.6311\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5979\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.6234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.6279\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.6047\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.6719\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.6118\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.6265\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.3796 | Test F1 (micro): 0.3796\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.6874\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.6459\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.6585\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.6091\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.6074\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5807\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.6407\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.6533\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.6387\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.6155\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.6360\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5553\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5915\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.6322\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.6701\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5732\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.5861\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.6103\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.5873\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.6176\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.5990\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.7035\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.5417\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5837\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.6127\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.5739\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.6494\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.5527\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.6352\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.5956\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.6125\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.6513\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.6147\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5656\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.5923\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.6263\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.6462\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.5801\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.6473\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.5580\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5595\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.6461\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.5927\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.6365\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.6174\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.6220\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.5528\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.6560\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5426\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.5888\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5652\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.6208\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.6197\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.5390\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.5642\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5999\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5714\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.6345\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.6274\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.5633\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.6251\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5813\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.5921\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.5856\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.5773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.6154\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.5418\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.5925\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.6470\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.5620\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5829\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.6061\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.6067\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.6250\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.6130\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.5942\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.4931\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.5450\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5863\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.5513\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.5466\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.6215\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.6133\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5923\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.5696\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5739\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.5486\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.6012\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.5718\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5700\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.5575\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.5320\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5519\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5526\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.5212\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.5861\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.5957\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.6514\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.4921\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.5836\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5265 | Test F1 (micro): 0.5265\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.5512\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5726\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.5802\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.5690\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.6099\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.6046\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5988\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.6042\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5614\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.6364\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.6000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5968\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5926\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5497\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.5764\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5281\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.5317\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.5675\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.5897\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.5976\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.5813\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.5563\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.4973\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5827\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.5798\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.5812\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5428\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.6083\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.6191\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.6407\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.5963\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.5683\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.5236\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5750\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.5238\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.4883\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.5163\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.5608\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.5634\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.5369\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5033\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.6196\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.5954\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5604\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.5341\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.4829\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.5002\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5762\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5150\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.5234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5799\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.5538\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4993\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.5429\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.5513\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5219\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5677\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.5462\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.5349\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.4786\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.5607\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5649\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.4732\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.6003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.4630\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5430\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.5440\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.4671\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.4653\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.5198\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5528\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5306\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.5760\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.5717\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.4614\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.5534\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5104\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.4771\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5965\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.6438\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.5109\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5809\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.5667\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5919\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.5438\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5900\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.5575\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.5550\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.5414\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5859\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.5176\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.4949\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5671\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5695\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.5634\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.6006\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.4798\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5810\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.5040\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.5387\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5047 | Test F1 (micro): 0.5047\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.5177\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.5466\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.5646\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.5568\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5282\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5729\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.4432\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5822\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4978\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.5453\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5596\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5613\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5145\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.5466\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.4897\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.4649\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.5600\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.4736\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.4961\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4941\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.4823\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.5433\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.4735\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.4817\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.5008\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5281\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.5862\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.5417\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.5615\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.6007\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.4543\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.5434\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5035\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.6350\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.5671\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.5610\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.5445\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.4555\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.5985\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5390\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.5466\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.5904\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.5252\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.4778\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.4380\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5298\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.4649\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.4487\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5317\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.5021\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4790\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.4557\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.4933\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5045\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.4863\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.5167\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.5188\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.4793\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.4986\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5223\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.4738\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.5235\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.5675\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5763\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.5387\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.5339\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.5304\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.4764\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5410\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5552\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.5201\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.5719\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.5000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.4890\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5471\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.5333\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5487\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.5223\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.5488\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5114\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.5646\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5148\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.4826\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5104\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.5547\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.5101\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.4788\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5373\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.4818\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.5441\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5167\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5021\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.5057\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.5003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.5084\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5454\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.4855\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.4711\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5629 | Test F1 (micro): 0.5629\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.5232\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.4868\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.5497\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.4910\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.4808\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.4121\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.4497\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5459\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4947\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.4858\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5711\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5160\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5336\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.5125\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.4982\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.5109\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.4578\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.4779\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4285\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.5519\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.5518\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5621\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.5270\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.6005\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5407\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.5376\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.5284\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.4712\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.5160\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.4758\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.4534\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5321\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.4189\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.5453\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.5723\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.4854\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.5095\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.5815\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5183\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.4869\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.4842\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5136\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.5431\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.4825\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.5282\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.4501\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5759\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.5190\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5127\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.4435\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4869\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.4992\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.4975\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5089\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5606\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.4720\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.5090\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.4945\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.5244\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.4776\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.4976\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.4987\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.4682\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5390\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.4552\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.5569\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.5390\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.5210\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.4648\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.4765\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.4400\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.5354\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.4826\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.5042\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.4096\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.5394\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5507\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.5197\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.4954\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5348\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.5439\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.4773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.4386\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.4530\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.5420\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.4627\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.5052\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5102\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.4735\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.4409\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5168\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5561\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.3993\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.4837\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.5310\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5309\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.4959\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.5778\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5956 | Test F1 (micro): 0.5956\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.4686\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5614\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.4314\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.4537\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.4108\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5246\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5634\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.4312\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5404\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.5004\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.5238\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.4836\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5215\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5866\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.5041\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5682\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.4674\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.4836\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.4975\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.5467\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4852\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.5248\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.5109\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5275\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.5162\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.5388\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5251\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.4204\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.4829\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.5351\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.4675\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.5158\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.5055\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.4433\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.4954\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.4980\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.4885\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.4867\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.4820\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.4963\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5138\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.5605\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.4546\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.4906\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.4899\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.5276\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.4865\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5127\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5933\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.5515\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5670\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.5408\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.5686\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.4430\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.5656\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5388\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5834\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.5328\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.4698\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.4969\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.4158\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5704\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.5631\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.5906\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.6214\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.4734\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.5628\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.4689\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.5506\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.4994\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5024\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5768\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.5009\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.4856\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.5391\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.5718\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5154\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.5476\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5593\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.5442\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.6528\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5482\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.5479\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5135\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.4942\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.4887\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.5104\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.5165\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.5075\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.6003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.5179\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.5840\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.4652\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5822\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.6105\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.5405\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.5086\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5896\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.5142\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.4897\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5644 | Test F1 (micro): 0.5644\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.5448\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5114\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.5551\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.5031\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.5293\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5344\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5215\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.5310\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5465\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4783\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.5299\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5612\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5025\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.4928\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.4934\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5003\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.5732\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.5216\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.4890\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.5236\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4757\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.4829\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.5127\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5575\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.5113\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.4503\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5350\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.5123\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.5073\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.5384\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.4923\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.5813\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.5347\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5389\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.4678\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.5001\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.5207\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.4575\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.4379\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.5350\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.4902\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.5013\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.5286\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5710\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.5423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.5083\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.5283\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5105\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5840\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.4657\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5286\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.5509\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4714\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.5296\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.4766\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.5690\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5631\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.5197\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.5500\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.4630\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.5360\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.4864\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.5408\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.5237\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.5256\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5017\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.5326\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.5205\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.5325\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.4699\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.4664\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5338\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.4783\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.5338\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.4971\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.4376\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5546\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.4754\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.4607\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.5681\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.5022\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5448\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.4735\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5147\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.5001\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5913\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.4560\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.4382\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.4747\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5030\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.5773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.5404\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5071\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5102\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.5695\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.4901\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.5146\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.4931\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.5222\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.4924\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5993 | Test F1 (micro): 0.5993\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.5393\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5552\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.4689\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.4861\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.4822\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5902\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.4812\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.5168\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.4940\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4637\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.5092\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5053\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.4880\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5014\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.4712\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.4423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.5178\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.5303\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.4783\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.5578\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4959\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.5899\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.6706\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.6153\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.6118\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.6554\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5307\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.6413\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.5486\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.5361\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.5450\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.5415\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.4966\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5056\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.5780\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.5515\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.4356\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.4760\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.5304\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.4203\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.4498\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.5877\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.4277\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5505\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.5149\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.4729\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.4770\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5482\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5109\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.4761\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.4993\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.5188\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4993\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.5553\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.4442\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.4998\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.5296\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.5042\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.5835\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.5529\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.4423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5201\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.5081\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.4481\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.5514\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5495\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.4816\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.4797\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.4842\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.5270\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5428\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.5430\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.4961\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.4921\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.4905\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.4941\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5302\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.4744\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.5345\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.4972\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.4681\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5182\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.4724\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5427\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.4496\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5565\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.6661\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.5195\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.4688\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5402\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.4879\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.4569\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5486\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.6024\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.5188\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.4092\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5053\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.5566\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.5132\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5309 | Test F1 (micro): 0.5309\")\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 1.4739\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 1.5809\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 1.5450\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 1.4879\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 1.5580\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 1.5814\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 1.5809\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 1.4810\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 1.5022\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 1.4834\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 1.4260\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 1.5194\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 1.5073\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 1.5086\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 1.5447\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 1.5409\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 1.5755\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 1.4661\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 1.5051\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 1.4305\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 1.4993\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 1.5057\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 1.4695\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 1.5170\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 1.5000\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 1.5202\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 1.5194\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 1.4839\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 1.5067\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 1.3975\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 1.5318\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 1.4998\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 1.5108\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 1.5584\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 1.4890\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 1.5101\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 1.4900\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 1.5535\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 1.4376\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 1.4696\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 1.5170\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 1.5029\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 1.5352\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 1.5552\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 1.4881\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 1.5712\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 1.5187\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 1.5104\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 1.5363\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 1.4911\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 1.5211\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 1.4981\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 1.4883\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 1.5835\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 1.5186\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 1.4411\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 1.4605\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 1.4861\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 1.4959\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 1.5463\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 1.5530\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 1.5665\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 1.5322\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 1.5760\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 1.5277\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 1.5241\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 1.4689\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 1.4756\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 1.5662\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 1.5061\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 1.5234\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 1.4908\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 1.4336\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 1.5100\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 1.4675\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 1.5008\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 1.5294\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 1.4576\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 1.4569\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 1.4923\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 1.4865\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 1.5767\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 1.4869\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 1.5593\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 1.4886\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 1.5096\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 1.4888\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 1.4455\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 1.4940\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 1.5073\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 1.4930\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 1.5275\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 1.5142\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 1.5025\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 1.4674\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 1.4703\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 1.4608\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 1.5105\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 1.6366\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 1.5314\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.5702 | Test F1 (micro): 0.5702\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_acc = np.std(res)\n",
        "mean_test_acc = np.mean(res)\n",
        "print(f\"Test Accuracy: {mean_test_acc:.4f} ± {std_acc:.4f}\")\n",
        "std_training = np.std(training)\n",
        "mean_training = np.mean(training)\n",
        "print(f\"training time: {mean_training:.4f} ± {std_training:.4f}\")"
      ],
      "metadata": {
        "id": "0HcweY9gTuZu",
        "outputId": "ffae8791-a5a6-4e4b-d750-71e1cf269a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5201 ± 0.0786\n",
            "training time: 2.1675 ± 0.2542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peak_memory_mb=f\"{torch.cuda.max_memory_allocated()/1024**2:.2f}\"\n",
        "total_train_time=f\"{end_time - start_time:.2f}\"\n",
        "\n",
        "metrics = {\n",
        "    \"model\": \"graphSAINT\",\n",
        "    \"accuracy\": test_acc,\n",
        "    \"f1_micro\":f1_micro,\n",
        "    \"peak_memory_MB\": peak_memory_mb,\n",
        "    \"train_time_sec\": total_train_time,\n",
        "    \"mem_MB\":79.58\n",
        "}\n",
        "\n",
        "with open(\"graphSAINT_rw_amazon_results.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)"
      ],
      "metadata": {
        "id": "LglZ26elp4kG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}