{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHW8b+yNcisJQAGAY63P8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghommidhWassim/GNN-variants/blob/main/graphSaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install torchvision\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MxXKQdoYf_",
        "outputId": "f57169bd-4784-4358-9f46-db153a76f0c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "2.6.0+cu124\n",
            "12.4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt26cu124)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cu124)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ruzytV_Nk9LG"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio --quiet\n",
        "# !pip install scipy numpy --quiet\n",
        "# !git clone https://github.com/graphsaint/graphsaint.git  # if you want to use official repo, or upload your own files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import time\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import GraphSAINTNodeSampler, GraphSAINTEdgeSampler, GraphSAINTRandomWalkSampler\n",
        "\n",
        "# (You will have to upload or place the GraphSAINT modules or install them if available)\n",
        "# For simplicity, assume graphsaint package is already in your environment or uploaded as files.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "def dataset_load():\n",
        "    print(f\"Using device: {device}\")\n",
        "    dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    return dataset.num_features, data, dataset.num_classes\n",
        "\n",
        "num_features, data, num_classes = dataset_load()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqMSSoVJ0rXT",
        "outputId": "4f2f4f83-a42f-471d-9196-5bea68218051"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJTVRr2c_kYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.cpu()\n",
        "loader_SAINT_256_node = GraphSAINTNodeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "loader_SAINT_256_edge = GraphSAINTEdgeSampler(data, batch_size=500, num_steps=4, sample_coverage=10)\n",
        "loader_SAINT_256_RW = GraphSAINTRandomWalkSampler(data, batch_size=500, walk_length=2, num_steps=4, sample_coverage=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhQYYlP5t8K",
        "outputId": "9cd1df29-ab86-43b6-d9cd-66eb0548e372"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Compute GraphSAINT normalization: : 198923it [00:00, 1427431.21it/s]                          \n",
            "Compute GraphSAINT normalization: : 198559it [02:57, 1120.79it/s]                          \n",
            "Compute GraphSAINT normalization: : 197723it [00:00, 1577181.40it/s]                          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, edge_weight=None):\n",
        "      x = self.conv1(x, edge_index, edge_weight)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=0.5, training=self.training)\n",
        "      x = self.conv2(x, edge_index, edge_weight)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "q75oq00V834G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channels=16).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "csFgXNhR_A7-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_norm)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# ------------------- Evaluation Function -------------------\n",
        "@torch.no_grad()\n",
        "def test(model, full_data):\n",
        "    model.eval()\n",
        "    out = model(full_data.x.to(device), full_data.edge_index.to(device))\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct = (pred[full_data.test_mask] == full_data.y[full_data.test_mask].to(device)).sum()\n",
        "    acc = int(correct) / int(full_data.test_mask.sum())\n",
        "    return acc\n",
        "\n",
        "# ------------------- Run Training -------------------\n",
        "def run(loader, method_name):\n",
        "    # Use the global num_classes variable instead of trying to access it from the data object\n",
        "\n",
        "\n",
        "    for epoch in range(1, 101):\n",
        "        loss = train(model, loader, optimizer, criterion)\n",
        "        print(f'{method_name} | Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    acc = test(model, data)\n",
        "    print(f'{method_name} | Final Test Accuracy: {acc:.4f}')\n",
        "\n",
        "# ------------------- Execute Training for Each Loader -------------------\n",
        "run(loader_SAINT_256_node, \"GraphSAINT-NodeSampler\")\n",
        "run(loader_SAINT_256_edge, \"GraphSAINT-EdgeSampler\")\n",
        "run(loader_SAINT_256_RW, \"GraphSAINT-RandomWalkSampler\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSiTzZo9Aaf",
        "outputId": "b3e11c4e-c4ec-478d-b9cd-c6717ec3a684"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAINT-NodeSampler | Epoch 001, Loss: 1.0800\n",
            "GraphSAINT-NodeSampler | Epoch 002, Loss: 1.0389\n",
            "GraphSAINT-NodeSampler | Epoch 003, Loss: 0.9962\n",
            "GraphSAINT-NodeSampler | Epoch 004, Loss: 0.9852\n",
            "GraphSAINT-NodeSampler | Epoch 005, Loss: 0.9144\n",
            "GraphSAINT-NodeSampler | Epoch 006, Loss: 0.8768\n",
            "GraphSAINT-NodeSampler | Epoch 007, Loss: 0.8602\n",
            "GraphSAINT-NodeSampler | Epoch 008, Loss: 0.8155\n",
            "GraphSAINT-NodeSampler | Epoch 009, Loss: 0.7646\n",
            "GraphSAINT-NodeSampler | Epoch 010, Loss: 0.7899\n",
            "GraphSAINT-NodeSampler | Epoch 011, Loss: 0.7397\n",
            "GraphSAINT-NodeSampler | Epoch 012, Loss: 0.6916\n",
            "GraphSAINT-NodeSampler | Epoch 013, Loss: 0.6595\n",
            "GraphSAINT-NodeSampler | Epoch 014, Loss: 0.6917\n",
            "GraphSAINT-NodeSampler | Epoch 015, Loss: 0.6286\n",
            "GraphSAINT-NodeSampler | Epoch 016, Loss: 0.6130\n",
            "GraphSAINT-NodeSampler | Epoch 017, Loss: 0.5892\n",
            "GraphSAINT-NodeSampler | Epoch 018, Loss: 0.6038\n",
            "GraphSAINT-NodeSampler | Epoch 019, Loss: 0.5945\n",
            "GraphSAINT-NodeSampler | Epoch 020, Loss: 0.5709\n",
            "GraphSAINT-NodeSampler | Epoch 021, Loss: 0.5704\n",
            "GraphSAINT-NodeSampler | Epoch 022, Loss: 0.5575\n",
            "GraphSAINT-NodeSampler | Epoch 023, Loss: 0.5469\n",
            "GraphSAINT-NodeSampler | Epoch 024, Loss: 0.5480\n",
            "GraphSAINT-NodeSampler | Epoch 025, Loss: 0.5509\n",
            "GraphSAINT-NodeSampler | Epoch 026, Loss: 0.5112\n",
            "GraphSAINT-NodeSampler | Epoch 027, Loss: 0.5725\n",
            "GraphSAINT-NodeSampler | Epoch 028, Loss: 0.5374\n",
            "GraphSAINT-NodeSampler | Epoch 029, Loss: 0.5322\n",
            "GraphSAINT-NodeSampler | Epoch 030, Loss: 0.5544\n",
            "GraphSAINT-NodeSampler | Epoch 031, Loss: 0.6765\n",
            "GraphSAINT-NodeSampler | Epoch 032, Loss: 0.5105\n",
            "GraphSAINT-NodeSampler | Epoch 033, Loss: 0.5183\n",
            "GraphSAINT-NodeSampler | Epoch 034, Loss: 0.5257\n",
            "GraphSAINT-NodeSampler | Epoch 035, Loss: 0.6466\n",
            "GraphSAINT-NodeSampler | Epoch 036, Loss: 0.4879\n",
            "GraphSAINT-NodeSampler | Epoch 037, Loss: 0.5248\n",
            "GraphSAINT-NodeSampler | Epoch 038, Loss: 0.5692\n",
            "GraphSAINT-NodeSampler | Epoch 039, Loss: 0.5104\n",
            "GraphSAINT-NodeSampler | Epoch 040, Loss: 0.5270\n",
            "GraphSAINT-NodeSampler | Epoch 041, Loss: 0.4661\n",
            "GraphSAINT-NodeSampler | Epoch 042, Loss: 0.4722\n",
            "GraphSAINT-NodeSampler | Epoch 043, Loss: 0.4772\n",
            "GraphSAINT-NodeSampler | Epoch 044, Loss: 0.4813\n",
            "GraphSAINT-NodeSampler | Epoch 045, Loss: 0.4993\n",
            "GraphSAINT-NodeSampler | Epoch 046, Loss: 0.5104\n",
            "GraphSAINT-NodeSampler | Epoch 047, Loss: 0.4871\n",
            "GraphSAINT-NodeSampler | Epoch 048, Loss: 0.4801\n",
            "GraphSAINT-NodeSampler | Epoch 049, Loss: 0.4770\n",
            "GraphSAINT-NodeSampler | Epoch 050, Loss: 0.5257\n",
            "GraphSAINT-NodeSampler | Epoch 051, Loss: 0.4624\n",
            "GraphSAINT-NodeSampler | Epoch 052, Loss: 0.4655\n",
            "GraphSAINT-NodeSampler | Epoch 053, Loss: 0.4593\n",
            "GraphSAINT-NodeSampler | Epoch 054, Loss: 0.4943\n",
            "GraphSAINT-NodeSampler | Epoch 055, Loss: 0.4413\n",
            "GraphSAINT-NodeSampler | Epoch 056, Loss: 0.4942\n",
            "GraphSAINT-NodeSampler | Epoch 057, Loss: 0.4656\n",
            "GraphSAINT-NodeSampler | Epoch 058, Loss: 0.4449\n",
            "GraphSAINT-NodeSampler | Epoch 059, Loss: 0.4457\n",
            "GraphSAINT-NodeSampler | Epoch 060, Loss: 0.4503\n",
            "GraphSAINT-NodeSampler | Epoch 061, Loss: 0.5149\n",
            "GraphSAINT-NodeSampler | Epoch 062, Loss: 0.5657\n",
            "GraphSAINT-NodeSampler | Epoch 063, Loss: 0.4442\n",
            "GraphSAINT-NodeSampler | Epoch 064, Loss: 0.5502\n",
            "GraphSAINT-NodeSampler | Epoch 065, Loss: 0.4484\n",
            "GraphSAINT-NodeSampler | Epoch 066, Loss: 0.5145\n",
            "GraphSAINT-NodeSampler | Epoch 067, Loss: 0.4359\n",
            "GraphSAINT-NodeSampler | Epoch 068, Loss: 0.4343\n",
            "GraphSAINT-NodeSampler | Epoch 069, Loss: 0.4317\n",
            "GraphSAINT-NodeSampler | Epoch 070, Loss: 0.4413\n",
            "GraphSAINT-NodeSampler | Epoch 071, Loss: 0.4191\n",
            "GraphSAINT-NodeSampler | Epoch 072, Loss: 0.8735\n",
            "GraphSAINT-NodeSampler | Epoch 073, Loss: 0.4388\n",
            "GraphSAINT-NodeSampler | Epoch 074, Loss: 0.4529\n",
            "GraphSAINT-NodeSampler | Epoch 075, Loss: 0.4436\n",
            "GraphSAINT-NodeSampler | Epoch 076, Loss: 0.4287\n",
            "GraphSAINT-NodeSampler | Epoch 077, Loss: 0.4017\n",
            "GraphSAINT-NodeSampler | Epoch 078, Loss: 0.4635\n",
            "GraphSAINT-NodeSampler | Epoch 079, Loss: 0.4645\n",
            "GraphSAINT-NodeSampler | Epoch 080, Loss: 0.4392\n",
            "GraphSAINT-NodeSampler | Epoch 081, Loss: 0.4134\n",
            "GraphSAINT-NodeSampler | Epoch 082, Loss: 0.5553\n",
            "GraphSAINT-NodeSampler | Epoch 083, Loss: 0.4427\n",
            "GraphSAINT-NodeSampler | Epoch 084, Loss: 0.5352\n",
            "GraphSAINT-NodeSampler | Epoch 085, Loss: 0.4214\n",
            "GraphSAINT-NodeSampler | Epoch 086, Loss: 0.5073\n",
            "GraphSAINT-NodeSampler | Epoch 087, Loss: 0.4404\n",
            "GraphSAINT-NodeSampler | Epoch 088, Loss: 0.3796\n",
            "GraphSAINT-NodeSampler | Epoch 089, Loss: 0.4255\n",
            "GraphSAINT-NodeSampler | Epoch 090, Loss: 0.4364\n",
            "GraphSAINT-NodeSampler | Epoch 091, Loss: 0.3969\n",
            "GraphSAINT-NodeSampler | Epoch 092, Loss: 0.4183\n",
            "GraphSAINT-NodeSampler | Epoch 093, Loss: 0.4251\n",
            "GraphSAINT-NodeSampler | Epoch 094, Loss: 0.4096\n",
            "GraphSAINT-NodeSampler | Epoch 095, Loss: 0.5523\n",
            "GraphSAINT-NodeSampler | Epoch 096, Loss: 0.4349\n",
            "GraphSAINT-NodeSampler | Epoch 097, Loss: 0.4193\n",
            "GraphSAINT-NodeSampler | Epoch 098, Loss: 0.5094\n",
            "GraphSAINT-NodeSampler | Epoch 099, Loss: 0.4508\n",
            "GraphSAINT-NodeSampler | Epoch 100, Loss: 0.6602\n",
            "GraphSAINT-NodeSampler | Final Test Accuracy: 0.8700\n",
            "GraphSAINT-EdgeSampler | Epoch 001, Loss: 0.8549\n",
            "GraphSAINT-EdgeSampler | Epoch 002, Loss: 0.8210\n",
            "GraphSAINT-EdgeSampler | Epoch 003, Loss: 0.6497\n",
            "GraphSAINT-EdgeSampler | Epoch 004, Loss: 0.5752\n",
            "GraphSAINT-EdgeSampler | Epoch 005, Loss: 0.6078\n",
            "GraphSAINT-EdgeSampler | Epoch 006, Loss: 0.6461\n",
            "GraphSAINT-EdgeSampler | Epoch 007, Loss: 0.5654\n",
            "GraphSAINT-EdgeSampler | Epoch 008, Loss: 0.5939\n",
            "GraphSAINT-EdgeSampler | Epoch 009, Loss: 0.5230\n",
            "GraphSAINT-EdgeSampler | Epoch 010, Loss: 0.5015\n",
            "GraphSAINT-EdgeSampler | Epoch 011, Loss: 0.6638\n",
            "GraphSAINT-EdgeSampler | Epoch 012, Loss: 0.5810\n",
            "GraphSAINT-EdgeSampler | Epoch 013, Loss: 0.5997\n",
            "GraphSAINT-EdgeSampler | Epoch 014, Loss: 0.4910\n",
            "GraphSAINT-EdgeSampler | Epoch 015, Loss: 0.5880\n",
            "GraphSAINT-EdgeSampler | Epoch 016, Loss: 0.6601\n",
            "GraphSAINT-EdgeSampler | Epoch 017, Loss: 0.7100\n",
            "GraphSAINT-EdgeSampler | Epoch 018, Loss: 0.6212\n",
            "GraphSAINT-EdgeSampler | Epoch 019, Loss: 0.6694\n",
            "GraphSAINT-EdgeSampler | Epoch 020, Loss: 0.6429\n",
            "GraphSAINT-EdgeSampler | Epoch 021, Loss: 0.6206\n",
            "GraphSAINT-EdgeSampler | Epoch 022, Loss: 0.6088\n",
            "GraphSAINT-EdgeSampler | Epoch 023, Loss: 0.6577\n",
            "GraphSAINT-EdgeSampler | Epoch 024, Loss: 0.5813\n",
            "GraphSAINT-EdgeSampler | Epoch 025, Loss: 0.5547\n",
            "GraphSAINT-EdgeSampler | Epoch 026, Loss: 0.5936\n",
            "GraphSAINT-EdgeSampler | Epoch 027, Loss: 0.6172\n",
            "GraphSAINT-EdgeSampler | Epoch 028, Loss: 0.5892\n",
            "GraphSAINT-EdgeSampler | Epoch 029, Loss: 0.5522\n",
            "GraphSAINT-EdgeSampler | Epoch 030, Loss: 0.5165\n",
            "GraphSAINT-EdgeSampler | Epoch 031, Loss: 0.4824\n",
            "GraphSAINT-EdgeSampler | Epoch 032, Loss: 0.5402\n",
            "GraphSAINT-EdgeSampler | Epoch 033, Loss: 0.5458\n",
            "GraphSAINT-EdgeSampler | Epoch 034, Loss: 0.5579\n",
            "GraphSAINT-EdgeSampler | Epoch 035, Loss: 0.5673\n",
            "GraphSAINT-EdgeSampler | Epoch 036, Loss: 0.5501\n",
            "GraphSAINT-EdgeSampler | Epoch 037, Loss: 0.5370\n",
            "GraphSAINT-EdgeSampler | Epoch 038, Loss: 0.7043\n",
            "GraphSAINT-EdgeSampler | Epoch 039, Loss: 0.7547\n",
            "GraphSAINT-EdgeSampler | Epoch 040, Loss: 0.5912\n",
            "GraphSAINT-EdgeSampler | Epoch 041, Loss: 0.7506\n",
            "GraphSAINT-EdgeSampler | Epoch 042, Loss: 0.5743\n",
            "GraphSAINT-EdgeSampler | Epoch 043, Loss: 0.5791\n",
            "GraphSAINT-EdgeSampler | Epoch 044, Loss: 0.5271\n",
            "GraphSAINT-EdgeSampler | Epoch 045, Loss: 0.5181\n",
            "GraphSAINT-EdgeSampler | Epoch 046, Loss: 0.5328\n",
            "GraphSAINT-EdgeSampler | Epoch 047, Loss: 0.5053\n",
            "GraphSAINT-EdgeSampler | Epoch 048, Loss: 0.4573\n",
            "GraphSAINT-EdgeSampler | Epoch 049, Loss: 0.5294\n",
            "GraphSAINT-EdgeSampler | Epoch 050, Loss: 0.5578\n",
            "GraphSAINT-EdgeSampler | Epoch 051, Loss: 0.5150\n",
            "GraphSAINT-EdgeSampler | Epoch 052, Loss: 0.4733\n",
            "GraphSAINT-EdgeSampler | Epoch 053, Loss: 0.4847\n",
            "GraphSAINT-EdgeSampler | Epoch 054, Loss: 0.4782\n",
            "GraphSAINT-EdgeSampler | Epoch 055, Loss: 0.6752\n",
            "GraphSAINT-EdgeSampler | Epoch 056, Loss: 0.6090\n",
            "GraphSAINT-EdgeSampler | Epoch 057, Loss: 0.5003\n",
            "GraphSAINT-EdgeSampler | Epoch 058, Loss: 0.4677\n",
            "GraphSAINT-EdgeSampler | Epoch 059, Loss: 0.4938\n",
            "GraphSAINT-EdgeSampler | Epoch 060, Loss: 0.4674\n",
            "GraphSAINT-EdgeSampler | Epoch 061, Loss: 0.5710\n",
            "GraphSAINT-EdgeSampler | Epoch 062, Loss: 0.5185\n",
            "GraphSAINT-EdgeSampler | Epoch 063, Loss: 0.5296\n",
            "GraphSAINT-EdgeSampler | Epoch 064, Loss: 0.5186\n",
            "GraphSAINT-EdgeSampler | Epoch 065, Loss: 0.6254\n",
            "GraphSAINT-EdgeSampler | Epoch 066, Loss: 0.7004\n",
            "GraphSAINT-EdgeSampler | Epoch 067, Loss: 0.5331\n",
            "GraphSAINT-EdgeSampler | Epoch 068, Loss: 0.6543\n",
            "GraphSAINT-EdgeSampler | Epoch 069, Loss: 0.7056\n",
            "GraphSAINT-EdgeSampler | Epoch 070, Loss: 0.5035\n",
            "GraphSAINT-EdgeSampler | Epoch 071, Loss: 0.5313\n",
            "GraphSAINT-EdgeSampler | Epoch 072, Loss: 0.4838\n",
            "GraphSAINT-EdgeSampler | Epoch 073, Loss: 0.5061\n",
            "GraphSAINT-EdgeSampler | Epoch 074, Loss: 0.6172\n",
            "GraphSAINT-EdgeSampler | Epoch 075, Loss: 0.5115\n",
            "GraphSAINT-EdgeSampler | Epoch 076, Loss: 0.5120\n",
            "GraphSAINT-EdgeSampler | Epoch 077, Loss: 0.5591\n",
            "GraphSAINT-EdgeSampler | Epoch 078, Loss: 0.5781\n",
            "GraphSAINT-EdgeSampler | Epoch 079, Loss: 0.5691\n",
            "GraphSAINT-EdgeSampler | Epoch 080, Loss: 0.5779\n",
            "GraphSAINT-EdgeSampler | Epoch 081, Loss: 0.6265\n",
            "GraphSAINT-EdgeSampler | Epoch 082, Loss: 0.4904\n",
            "GraphSAINT-EdgeSampler | Epoch 083, Loss: 0.4716\n",
            "GraphSAINT-EdgeSampler | Epoch 084, Loss: 0.6144\n",
            "GraphSAINT-EdgeSampler | Epoch 085, Loss: 0.4971\n",
            "GraphSAINT-EdgeSampler | Epoch 086, Loss: 0.5338\n",
            "GraphSAINT-EdgeSampler | Epoch 087, Loss: 0.5648\n",
            "GraphSAINT-EdgeSampler | Epoch 088, Loss: 0.4782\n",
            "GraphSAINT-EdgeSampler | Epoch 089, Loss: 0.5071\n",
            "GraphSAINT-EdgeSampler | Epoch 090, Loss: 0.4531\n",
            "GraphSAINT-EdgeSampler | Epoch 091, Loss: 0.5155\n",
            "GraphSAINT-EdgeSampler | Epoch 092, Loss: 0.5031\n",
            "GraphSAINT-EdgeSampler | Epoch 093, Loss: 0.6107\n",
            "GraphSAINT-EdgeSampler | Epoch 094, Loss: 0.5018\n",
            "GraphSAINT-EdgeSampler | Epoch 095, Loss: 0.4986\n",
            "GraphSAINT-EdgeSampler | Epoch 096, Loss: 0.5165\n",
            "GraphSAINT-EdgeSampler | Epoch 097, Loss: 0.4718\n",
            "GraphSAINT-EdgeSampler | Epoch 098, Loss: 0.4907\n",
            "GraphSAINT-EdgeSampler | Epoch 099, Loss: 0.4989\n",
            "GraphSAINT-EdgeSampler | Epoch 100, Loss: 0.5175\n",
            "GraphSAINT-EdgeSampler | Final Test Accuracy: 0.8380\n",
            "GraphSAINT-RandomWalkSampler | Epoch 001, Loss: 0.5637\n",
            "GraphSAINT-RandomWalkSampler | Epoch 002, Loss: 0.5471\n",
            "GraphSAINT-RandomWalkSampler | Epoch 003, Loss: 0.5377\n",
            "GraphSAINT-RandomWalkSampler | Epoch 004, Loss: 0.5282\n",
            "GraphSAINT-RandomWalkSampler | Epoch 005, Loss: 0.5043\n",
            "GraphSAINT-RandomWalkSampler | Epoch 006, Loss: 0.5157\n",
            "GraphSAINT-RandomWalkSampler | Epoch 007, Loss: 0.4647\n",
            "GraphSAINT-RandomWalkSampler | Epoch 008, Loss: 0.4789\n",
            "GraphSAINT-RandomWalkSampler | Epoch 009, Loss: 0.4572\n",
            "GraphSAINT-RandomWalkSampler | Epoch 010, Loss: 0.4550\n",
            "GraphSAINT-RandomWalkSampler | Epoch 011, Loss: 0.4763\n",
            "GraphSAINT-RandomWalkSampler | Epoch 012, Loss: 0.4685\n",
            "GraphSAINT-RandomWalkSampler | Epoch 013, Loss: 0.4781\n",
            "GraphSAINT-RandomWalkSampler | Epoch 014, Loss: 0.4510\n",
            "GraphSAINT-RandomWalkSampler | Epoch 015, Loss: 0.4558\n",
            "GraphSAINT-RandomWalkSampler | Epoch 016, Loss: 0.4773\n",
            "GraphSAINT-RandomWalkSampler | Epoch 017, Loss: 0.4676\n",
            "GraphSAINT-RandomWalkSampler | Epoch 018, Loss: 0.4746\n",
            "GraphSAINT-RandomWalkSampler | Epoch 019, Loss: 0.4335\n",
            "GraphSAINT-RandomWalkSampler | Epoch 020, Loss: 0.4802\n",
            "GraphSAINT-RandomWalkSampler | Epoch 021, Loss: 0.4420\n",
            "GraphSAINT-RandomWalkSampler | Epoch 022, Loss: 0.4361\n",
            "GraphSAINT-RandomWalkSampler | Epoch 023, Loss: 0.4830\n",
            "GraphSAINT-RandomWalkSampler | Epoch 024, Loss: 0.4904\n",
            "GraphSAINT-RandomWalkSampler | Epoch 025, Loss: 0.4621\n",
            "GraphSAINT-RandomWalkSampler | Epoch 026, Loss: 0.4597\n",
            "GraphSAINT-RandomWalkSampler | Epoch 027, Loss: 0.4477\n",
            "GraphSAINT-RandomWalkSampler | Epoch 028, Loss: 0.4480\n",
            "GraphSAINT-RandomWalkSampler | Epoch 029, Loss: 0.4540\n",
            "GraphSAINT-RandomWalkSampler | Epoch 030, Loss: 0.4745\n",
            "GraphSAINT-RandomWalkSampler | Epoch 031, Loss: 0.4615\n",
            "GraphSAINT-RandomWalkSampler | Epoch 032, Loss: 0.4638\n",
            "GraphSAINT-RandomWalkSampler | Epoch 033, Loss: 0.4413\n",
            "GraphSAINT-RandomWalkSampler | Epoch 034, Loss: 0.4565\n",
            "GraphSAINT-RandomWalkSampler | Epoch 035, Loss: 0.4775\n",
            "GraphSAINT-RandomWalkSampler | Epoch 036, Loss: 0.4489\n",
            "GraphSAINT-RandomWalkSampler | Epoch 037, Loss: 0.5171\n",
            "GraphSAINT-RandomWalkSampler | Epoch 038, Loss: 0.4540\n",
            "GraphSAINT-RandomWalkSampler | Epoch 039, Loss: 0.4644\n",
            "GraphSAINT-RandomWalkSampler | Epoch 040, Loss: 0.4563\n",
            "GraphSAINT-RandomWalkSampler | Epoch 041, Loss: 0.4574\n",
            "GraphSAINT-RandomWalkSampler | Epoch 042, Loss: 0.4589\n",
            "GraphSAINT-RandomWalkSampler | Epoch 043, Loss: 0.4674\n",
            "GraphSAINT-RandomWalkSampler | Epoch 044, Loss: 0.4496\n",
            "GraphSAINT-RandomWalkSampler | Epoch 045, Loss: 0.4282\n",
            "GraphSAINT-RandomWalkSampler | Epoch 046, Loss: 0.4737\n",
            "GraphSAINT-RandomWalkSampler | Epoch 047, Loss: 0.4610\n",
            "GraphSAINT-RandomWalkSampler | Epoch 048, Loss: 0.4530\n",
            "GraphSAINT-RandomWalkSampler | Epoch 049, Loss: 0.4400\n",
            "GraphSAINT-RandomWalkSampler | Epoch 050, Loss: 0.4333\n",
            "GraphSAINT-RandomWalkSampler | Epoch 051, Loss: 0.4700\n",
            "GraphSAINT-RandomWalkSampler | Epoch 052, Loss: 0.4224\n",
            "GraphSAINT-RandomWalkSampler | Epoch 053, Loss: 0.4594\n",
            "GraphSAINT-RandomWalkSampler | Epoch 054, Loss: 0.4451\n",
            "GraphSAINT-RandomWalkSampler | Epoch 055, Loss: 0.4431\n",
            "GraphSAINT-RandomWalkSampler | Epoch 056, Loss: 0.4760\n",
            "GraphSAINT-RandomWalkSampler | Epoch 057, Loss: 0.4354\n",
            "GraphSAINT-RandomWalkSampler | Epoch 058, Loss: 0.4656\n",
            "GraphSAINT-RandomWalkSampler | Epoch 059, Loss: 0.4286\n",
            "GraphSAINT-RandomWalkSampler | Epoch 060, Loss: 0.4357\n",
            "GraphSAINT-RandomWalkSampler | Epoch 061, Loss: 0.4373\n",
            "GraphSAINT-RandomWalkSampler | Epoch 062, Loss: 0.4596\n",
            "GraphSAINT-RandomWalkSampler | Epoch 063, Loss: 0.4461\n",
            "GraphSAINT-RandomWalkSampler | Epoch 064, Loss: 0.4257\n",
            "GraphSAINT-RandomWalkSampler | Epoch 065, Loss: 0.4476\n",
            "GraphSAINT-RandomWalkSampler | Epoch 066, Loss: 0.4304\n",
            "GraphSAINT-RandomWalkSampler | Epoch 067, Loss: 0.4337\n",
            "GraphSAINT-RandomWalkSampler | Epoch 068, Loss: 0.4382\n",
            "GraphSAINT-RandomWalkSampler | Epoch 069, Loss: 0.4527\n",
            "GraphSAINT-RandomWalkSampler | Epoch 070, Loss: 0.4372\n",
            "GraphSAINT-RandomWalkSampler | Epoch 071, Loss: 0.4788\n",
            "GraphSAINT-RandomWalkSampler | Epoch 072, Loss: 0.4630\n",
            "GraphSAINT-RandomWalkSampler | Epoch 073, Loss: 0.4494\n",
            "GraphSAINT-RandomWalkSampler | Epoch 074, Loss: 0.4386\n",
            "GraphSAINT-RandomWalkSampler | Epoch 075, Loss: 0.4497\n",
            "GraphSAINT-RandomWalkSampler | Epoch 076, Loss: 0.4488\n",
            "GraphSAINT-RandomWalkSampler | Epoch 077, Loss: 0.4414\n",
            "GraphSAINT-RandomWalkSampler | Epoch 078, Loss: 0.4636\n",
            "GraphSAINT-RandomWalkSampler | Epoch 079, Loss: 0.4577\n",
            "GraphSAINT-RandomWalkSampler | Epoch 080, Loss: 0.4461\n",
            "GraphSAINT-RandomWalkSampler | Epoch 081, Loss: 0.4516\n",
            "GraphSAINT-RandomWalkSampler | Epoch 082, Loss: 0.4409\n",
            "GraphSAINT-RandomWalkSampler | Epoch 083, Loss: 0.4251\n",
            "GraphSAINT-RandomWalkSampler | Epoch 084, Loss: 0.4404\n",
            "GraphSAINT-RandomWalkSampler | Epoch 085, Loss: 0.4496\n",
            "GraphSAINT-RandomWalkSampler | Epoch 086, Loss: 0.4364\n",
            "GraphSAINT-RandomWalkSampler | Epoch 087, Loss: 0.4087\n",
            "GraphSAINT-RandomWalkSampler | Epoch 088, Loss: 0.4410\n",
            "GraphSAINT-RandomWalkSampler | Epoch 089, Loss: 0.4222\n",
            "GraphSAINT-RandomWalkSampler | Epoch 090, Loss: 0.4343\n",
            "GraphSAINT-RandomWalkSampler | Epoch 091, Loss: 0.4235\n",
            "GraphSAINT-RandomWalkSampler | Epoch 092, Loss: 0.4201\n",
            "GraphSAINT-RandomWalkSampler | Epoch 093, Loss: 0.4549\n",
            "GraphSAINT-RandomWalkSampler | Epoch 094, Loss: 0.4432\n",
            "GraphSAINT-RandomWalkSampler | Epoch 095, Loss: 0.4423\n",
            "GraphSAINT-RandomWalkSampler | Epoch 096, Loss: 0.4430\n",
            "GraphSAINT-RandomWalkSampler | Epoch 097, Loss: 0.4332\n",
            "GraphSAINT-RandomWalkSampler | Epoch 098, Loss: 0.4304\n",
            "GraphSAINT-RandomWalkSampler | Epoch 099, Loss: 0.4276\n",
            "GraphSAINT-RandomWalkSampler | Epoch 100, Loss: 0.4649\n",
            "GraphSAINT-RandomWalkSampler | Final Test Accuracy: 0.8680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anderskm/gputil.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPUYqphbJk1E",
        "outputId": "80602db2-54b3-4fe4-d852-19572302ef04"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gputil'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Total 456 (delta 0), reused 0 (delta 0), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 83.68 KiB | 5.23 MiB/s, done.\n",
            "Resolving deltas: 100% (263/263), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gputil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAtqzeViJsuR",
        "outputId": "637c751d-12ee-4db1-afc5-454748830e03"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=035f0914f649f825d09f42aede1a7a0c9a5c3ac76e22b74fbc617df8c233a80b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GPUtil\n",
        "GPUtil.showUtilization()\n",
        "GPUs = GPUtil.getGPUs()\n",
        "GPUs[0].memoryUsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbLB_-TnJ-0R",
        "outputId": "cb82b935-5107-4001-a418-9455db1bb44f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  2% |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256.0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "print(f\"Max GPU memory used:  {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOWkhJt4OEC3",
        "outputId": "4f76fe7d-c4d5-43b2-d8f0-d108d4135c54"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated: 16.38 MB\n",
            "Max GPU memory used:  113.66 MB\n"
          ]
        }
      ]
    }
  ]
}